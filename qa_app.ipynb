{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "620aff6b-9591-4587-b8e5-06886b21d403",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.retrievers import AmazonKendraRetriever\n",
    "\n",
    "from langchain import SQLDatabase\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "\n",
    "import os\n",
    "import boto3\n",
    "\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = \"us-east-1\"  # E.g. \"us-east-1\"\n",
    "# os.environ[\"AWS_PROFILE\"] = \"bedrock_claude\"\n",
    "os.environ[\"BEDROCK_ENDPOINT_URL\"] = \"https://bedrock-runtime.us-east-1.amazonaws.com\"  # E.g. \"https://...\"\n",
    "\n",
    "session = boto3.Session(\n",
    "    profile_name=os.environ.get(\"AWS_PROFILE\")\n",
    ") # sets the profile name to use for AWS credentials\n",
    "\n",
    "bedrock = session.client(\n",
    "    service_name='bedrock-runtime', # creates a Bedrock client\n",
    "    region_name=os.environ.get(\"AWS_DEFAULT_REGION\"),\n",
    "    endpoint_url=os.environ.get(\"BEDROCK_ENDPOINT_URL\")\n",
    ") \n",
    "\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "\n",
    "# - create the Anthropic Model\n",
    "llm = Bedrock(model_id=\"anthropic.claude-v2\", client=bedrock, model_kwargs={'max_tokens_to_sample':1000, 'temperature': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8c1b8a9-f4a7-45be-9dc2-c5338ff2cd67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kendra_index_id = \"<YOUR_KENDRA_INDEX>\" # Example: 65702b79-bbae-4c93-b45b-9702f17fb994\n",
    "kendra_index_id = \"458952bb-3b13-4dc4-9321-e625b077bab9\"\n",
    "\n",
    "retriever = AmazonKendraRetriever(\n",
    "    index_id=kendra_index_id,\n",
    "    region_name=os.environ.get(\"AWS_DEFAULT_REGION\", None),\n",
    "    top_k=3,\n",
    "    attribute_filter = {\n",
    "        \"EqualsTo\": {      \n",
    "            \"Key\": \"_language_code\",\n",
    "            \"Value\": {\n",
    "                \"StringValue\": \"ko\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5633d2c5-78e2-4f58-a8a9-9f3a66cbd883",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "\n",
    "Human: This is a friendly conversation between a human and an AI. \n",
    "The AI is talkative and provides specific details from its context but limits it to 240 tokens.\n",
    "If the AI does not know the answer to a question, it truthfully says it \n",
    "does not know.\n",
    "\n",
    "Assistant: OK, got it, I'll be a talkative truthful AI assistant.\n",
    "\n",
    "Human: Here are a few documents in <documents> tags:\n",
    "<documents>\n",
    "{context}\n",
    "</documents>\n",
    "Based on the above documents, provide a detailed answer for, {question} \n",
    "Answer \"시스템에 관련된 정보가 없습니다.\" if not present in the document. \n",
    "\n",
    "Assistant:\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca9a0505-fc08-455f-a98f-84ca2e29dfd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": PROMPT}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a09e7744-1ab4-40b3-9834-6cd3ae82f058",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.42 ms, sys: 3.77 ms, total: 13.2 ms\n",
      "Wall time: 10.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "query = \"근무시간 알려줘\"\n",
    "result = qa({\"query\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62511b1c-1116-44ed-894d-1c64d251493c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 문서에 따르면,\n",
      "\n",
      "- 주중 근무 시간은 대부분 매장에서 오전 9시부터 오후 9시까지입니다. \n",
      "\n",
      "- 주말에도 영업하는 매장에서는 주말에도 근무가 있으며, 주말 근무는 로테이션 제도가 적용될 수 있습니다.\n",
      "\n",
      "- 대형 매장의 경우 교대 근무 제도가 적용되어 오전/오후 교대 근무가 있습니다.\n",
      "\n",
      "- 일부 직원은 시간제 근무를 통해 유연한 근무 시간을 가질 수 있습니다.\n",
      "\n",
      "- 근무 스케줄은 매장 관리자나 인사팀에서 주간/월간으로 작성하며 미리 안내됩니다. \n",
      "\n",
      "- 휴가나 휴식 시간도 스케줄에 고려됩니다.\n",
      "\n",
      "이상이 근무 시간에 대한 주요 내용입니다. 시스템에 대한 구체적인 언급은 문서에 없는 것 같습니다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Document Title: 근무 시간과 스케줄.docx\\nDocument Excerpt: \\n1. 근무 시간: · 주중 근무: 대부분의 매장은 주중에 영업하며, 근무 시간은 보통 오전 9시부터 오후 9시까지입니다. 다만, 이 시간은 매장 및 지역에 따라 다를 수 있습니다. · 주말 근무: 주말에도 영업하는 매장의 경우 직원은 주말에 근무할 수 있으며, 주말 근무 로테이션 시스템이 적용될 수 있습니다. · 교대 근무: 대형 매장의 경우, 교대 근무 시스템을 운영하여 오전 근무와 오후 근무로 나누어 직원의 피로를 분산시킬 수 있습니다. · 시간제 근무: 일부 직원들은 시간제 근무를 통해 풀타임 또는 파트타임으로 근무할 수 있으며, 이에 따라 근무 시간이 유연하게 조절됩니다. 2. 스케줄: · 스케줄 작성: 매장 관리자 또는 인사팀은 직원들의 스케줄을 작성합니다. 이는 주간 또는 월간 스케줄로 작성될 수 있으며, 직원들에게 미리 통보됩니다.\\n', metadata={'result_id': '44f4a173-5117-41b0-9803-88227d128577-3bbc5e16-09d7-4a8e-95bb-6a69c157dfde', 'document_id': 's3://kendra-for-workshop-d44bb6c0-767f-11ee-9d7b-0ea1c2170c63/근무 시간과 스케줄.docx', 'source': 'https://kendra-for-workshop-d44bb6c0-767f-11ee-9d7b-0ea1c2170c63.s3.amazonaws.com/%E1%84%80%E1%85%B3%E1%86%AB%E1%84%86%E1%85%AE%20%E1%84%89%E1%85%B5%E1%84%80%E1%85%A1%E1%86%AB%E1%84%80%E1%85%AA%20%E1%84%89%E1%85%B3%E1%84%8F%E1%85%A6%E1%84%8C%E1%85%AE%E1%86%AF.docx', 'title': '근무 시간과 스케줄.docx', 'excerpt': '1. 근무 시간: · 주중 근무: 대부분의 매장은 주중에 영업하며, 근무 시간은 보통 오전 9시부터 오후 9시까지입니다. 다만, 이 시간은 매장 및 지역에 따라 다를 수 있습니다. · 주말 근무: 주말에도 영업하는 매장의 경우 직원은 주말에 근무할 수 있으며, 주말 근무 로테이션 시스템이 적용될 수 있습니다. · 교대 근무: 대형 매장의 경우, 교대 근무 시스템을 운영하여 오전 근무와 오후 근무로 나누어 직원의 피로를 분산시킬 수 있습니다. · 시간제 근무: 일부 직원들은 시간제 근무를 통해 풀타임 또는 파트타임으로 근무할 수 있으며, 이에 따라 근무 시간이 유연하게 조절됩니다. 2. 스케줄: · 스케줄 작성: 매장 관리자 또는 인사팀은 직원들의 스케줄을 작성합니다. 이는 주간 또는 월간 스케줄로 작성될 수 있으며, 직원들에게 미리 통보됩니다.', 'document_attributes': {'_source_uri': 'https://kendra-for-workshop-d44bb6c0-767f-11ee-9d7b-0ea1c2170c63.s3.amazonaws.com/%E1%84%80%E1%85%B3%E1%86%AB%E1%84%86%E1%85%AE%20%E1%84%89%E1%85%B5%E1%84%80%E1%85%A1%E1%86%AB%E1%84%80%E1%85%AA%20%E1%84%89%E1%85%B3%E1%84%8F%E1%85%A6%E1%84%8C%E1%85%AE%E1%86%AF.docx', 's3_document_id': '근무 시간과 스케줄.docx'}}),\n",
       " Document(page_content='Document Title: 일일 근무 시간 및 주간 근무 일정 규정.docx\\nDocument Excerpt: \\n근무 일정 - 주간 근무: 월요일부터 금요일까지 - 주말 근무: 토요일과 일요일 (로테이션 시스템에 따라 교대 근무) - 주 5일 근무: 월요일부터 금요일까지 근무, 주말 휴무 - 주 6일 근무: 월요일부터 토요일까지 근무, 일요일 휴무 - 교대 근무: 일부 직원들은 주간과 야간 근무를 교대로 진행 휴가 및 휴일 - 연차 휴가: 연간 15일, 근무 연수에 따라 추가 휴가 지급 - 법정 공휴일: 국가의 법정 공휴일에 따라 휴무 - 연말 연시 휴가: 12월 31일부터 1월 1일까지 휴가 - 기타 휴가 정책: 병가, 출산휴가, 경조사 휴가 등을 포함 근무 시간 조정 - 재택 근무 정책: 특정 업무에 한하여 원격 근무 가능 - 유연 근무 시간: 일부 직원들에게 유연한 근무 시간 제공 - 교대 근무: 주간과 야간 근무를 교대로 조정 가능 휴게시간 및 휴일근무 - 휴게시간: 1시간의 식사 휴게시간 제공 - 휴일근무 수당: 공휴일에 근무하는 경우 추가 수당 제공 - 주말근무 수당: 주말 근무 시 추가 수당 제공\\n', metadata={'result_id': '44f4a173-5117-41b0-9803-88227d128577-71eb00dc-cbef-4af5-9351-275200ab5818', 'document_id': 's3://kendra-for-workshop-d44bb6c0-767f-11ee-9d7b-0ea1c2170c63/일일 근무 시간 및 주간 근무 일정 규정.docx', 'source': 'https://kendra-for-workshop-d44bb6c0-767f-11ee-9d7b-0ea1c2170c63.s3.amazonaws.com/%E1%84%8B%E1%85%B5%E1%86%AF%E1%84%8B%E1%85%B5%E1%86%AF%20%E1%84%80%E1%85%B3%E1%86%AB%E1%84%86%E1%85%AE%20%E1%84%89%E1%85%B5%E1%84%80%E1%85%A1%E1%86%AB%20%E1%84%86%E1%85%B5%E1%86%BE%20%E1%84%8C%E1%85%AE%E1%84%80%E1%85%A1%E1%86%AB%20%E1%84%80%E1%85%B3%E1%86%AB%E1%84%86%E1%85%AE%20%E1%84%8B%E1%85%B5%E1%86%AF%E1%84%8C%E1%85%A5%E1%86%BC%20%E1%84%80%E1%85%B2%E1%84%8C%E1%85%A5%E1%86%BC.docx', 'title': '일일 근무 시간 및 주간 근무 일정 규정.docx', 'excerpt': '근무 일정\\t- 주간 근무: 월요일부터 금요일까지 - 주말 근무: 토요일과 일요일 (로테이션 시스템에 따라 교대 근무) - 주 5일 근무: 월요일부터 금요일까지 근무, 주말 휴무 - 주 6일 근무: 월요일부터 토요일까지 근무, 일요일 휴무 - 교대 근무: 일부 직원들은 주간과 야간 근무를 교대로 진행 휴가 및 휴일\\t- 연차 휴가: 연간 15일, 근무 연수에 따라 추가 휴가 지급 - 법정 공휴일: 국가의 법정 공휴일에 따라 휴무 - 연말 연시 휴가: 12월 31일부터 1월 1일까지 휴가 - 기타 휴가 정책: 병가, 출산휴가, 경조사 휴가 등을 포함 근무 시간 조정\\t- 재택 근무 정책: 특정 업무에 한하여 원격 근무 가능 - 유연 근무 시간: 일부 직원들에게 유연한 근무 시간 제공 - 교대 근무: 주간과 야간 근무를 교대로 조정 가능 휴게시간 및 휴일근무\\t- 휴게시간: 1시간의 식사 휴게시간 제공 - 휴일근무 수당: 공휴일에 근무하는 경우 추가 수당 제공 - 주말근무 수당: 주말 근무 시 추가 수당 제공', 'document_attributes': {'_source_uri': 'https://kendra-for-workshop-d44bb6c0-767f-11ee-9d7b-0ea1c2170c63.s3.amazonaws.com/%E1%84%8B%E1%85%B5%E1%86%AF%E1%84%8B%E1%85%B5%E1%86%AF%20%E1%84%80%E1%85%B3%E1%86%AB%E1%84%86%E1%85%AE%20%E1%84%89%E1%85%B5%E1%84%80%E1%85%A1%E1%86%AB%20%E1%84%86%E1%85%B5%E1%86%BE%20%E1%84%8C%E1%85%AE%E1%84%80%E1%85%A1%E1%86%AB%20%E1%84%80%E1%85%B3%E1%86%AB%E1%84%86%E1%85%AE%20%E1%84%8B%E1%85%B5%E1%86%AF%E1%84%8C%E1%85%A5%E1%86%BC%20%E1%84%80%E1%85%B2%E1%84%8C%E1%85%A5%E1%86%BC.docx', 's3_document_id': '일일 근무 시간 및 주간 근무 일정 규정.docx'}}),\n",
       " Document(page_content='Document Title: 근무 시간과 스케줄.docx\\nDocument Excerpt: \\n1. 근무 시간: · 주중 근무: 대부분의 매장은 주중에 영업하며, 근무 시간은 보통 오전 9시부터 오후 9시까지입니다. 다만, 이 시간은 매장 및 지역에 따라 다를 수 있습니다. · 주말 근무: 주말에도 영업하는 매장의 경우 직원은 주말에 근무할 수 있으며, 주말 근무 로테이션 시스템이 적용될 수 있습니다. · 교대 근무: 대형 매장의 경우, 교대 근무 시스템을 운영하여 오전 근무와 오후 근무로 나누어 직원의 피로를 분산시킬 수 있습니다. · 시간제 근무: 일부 직원들은 시간제 근무를 통해 풀타임 또는 파트타임으로 근무할 수 있으며, 이에 따라 근무 시간이 유연하게 조절됩니다. 2. 스케줄: · 스케줄 작성: 매장 관리자 또는 인사팀은 직원들의 스케줄을 작성합니다. 이는 주간 또는 월간 스케줄로 작성될 수 있으며, 직원들에게 미리 통보됩니다. · 휴가 및 휴식: 직원들은 휴가를 신청할 수 있으며, 스케줄 작성 시 고려됩니다. 또한, 근무 시간 내에 휴식 시간이 제공되어야 합니다. · 스케줄 변경: 스케줄 변경이 필요한 경우, 미리 상사나 인사팀에게 요청하고 승인을 받아야 합니다. · 교대근무: 교대 근무 시스템을 적용하는 경우, 근무자 간의 교대 근무 일정이 스케줄에 포함됩니다. · 팀 협력: 직원들은 스케줄을 준수하고 팀원들과의 협력을 통해 매장 운영을 원활하게 진행해야 합니다.\\n', metadata={'result_id': '44f4a173-5117-41b0-9803-88227d128577-3db14c64-daf2-45d2-8f59-a5ff452b14f0', 'document_id': 's3://kendra-for-workshop-d44bb6c0-767f-11ee-9d7b-0ea1c2170c63/근무 시간과 스케줄.docx', 'source': 'https://kendra-for-workshop-d44bb6c0-767f-11ee-9d7b-0ea1c2170c63.s3.amazonaws.com/%E1%84%80%E1%85%B3%E1%86%AB%E1%84%86%E1%85%AE%20%E1%84%89%E1%85%B5%E1%84%80%E1%85%A1%E1%86%AB%E1%84%80%E1%85%AA%20%E1%84%89%E1%85%B3%E1%84%8F%E1%85%A6%E1%84%8C%E1%85%AE%E1%86%AF.docx', 'title': '근무 시간과 스케줄.docx', 'excerpt': '1. 근무 시간: · 주중 근무: 대부분의 매장은 주중에 영업하며, 근무 시간은 보통 오전 9시부터 오후 9시까지입니다. 다만, 이 시간은 매장 및 지역에 따라 다를 수 있습니다. · 주말 근무: 주말에도 영업하는 매장의 경우 직원은 주말에 근무할 수 있으며, 주말 근무 로테이션 시스템이 적용될 수 있습니다. · 교대 근무: 대형 매장의 경우, 교대 근무 시스템을 운영하여 오전 근무와 오후 근무로 나누어 직원의 피로를 분산시킬 수 있습니다. · 시간제 근무: 일부 직원들은 시간제 근무를 통해 풀타임 또는 파트타임으로 근무할 수 있으며, 이에 따라 근무 시간이 유연하게 조절됩니다. 2. 스케줄: · 스케줄 작성: 매장 관리자 또는 인사팀은 직원들의 스케줄을 작성합니다. 이는 주간 또는 월간 스케줄로 작성될 수 있으며, 직원들에게 미리 통보됩니다. · 휴가 및 휴식: 직원들은 휴가를 신청할 수 있으며, 스케줄 작성 시 고려됩니다. 또한, 근무 시간 내에 휴식 시간이 제공되어야 합니다. · 스케줄 변경: 스케줄 변경이 필요한 경우, 미리 상사나 인사팀에게 요청하고 승인을 받아야 합니다. · 교대근무: 교대 근무 시스템을 적용하는 경우, 근무자 간의 교대 근무 일정이 스케줄에 포함됩니다. · 팀 협력: 직원들은 스케줄을 준수하고 팀원들과의 협력을 통해 매장 운영을 원활하게 진행해야 합니다.', 'document_attributes': {'_source_uri': 'https://kendra-for-workshop-d44bb6c0-767f-11ee-9d7b-0ea1c2170c63.s3.amazonaws.com/%E1%84%80%E1%85%B3%E1%86%AB%E1%84%86%E1%85%AE%20%E1%84%89%E1%85%B5%E1%84%80%E1%85%A1%E1%86%AB%E1%84%80%E1%85%AA%20%E1%84%89%E1%85%B3%E1%84%8F%E1%85%A6%E1%84%8C%E1%85%AE%E1%86%AF.docx', 's3_document_id': '근무 시간과 스케줄.docx'}})]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(result['result'])\n",
    "result['source_documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67cd3dc-7aad-400d-a953-00b48466be5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile kendra_claude.py\n",
    "\n",
    "from langchain.retrievers import AmazonKendraRetriever\n",
    "from langchain.prompts import PromptTemplate\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import boto3\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "\n",
    "def build_chain():\n",
    "\n",
    "  session = boto3.Session(\n",
    "      profile_name=os.environ.get(\"AWS_PROFILE\")\n",
    "  ) \n",
    "  boto3_bedrock = session.client(\n",
    "    service_name='bedrock-runtime', \n",
    "    region_name=os.environ.get(\"AWS_DEFAULT_REGION\"),\n",
    "    endpoint_url=os.environ.get(\"BEDROCK_ENDPOINT_URL\")\n",
    "  ) \n",
    "    \n",
    "  region = os.environ[\"AWS_REGION\"]\n",
    "  kendra_index_id = \"<YOUR_KENDRA_INDEX>\" # Example: 65702b79-bbae-4c93-b45b-9702f17fb994\n",
    "  kendra_index_id = \"458952bb-3b13-4dc4-9321-e625b077bab9\"\n",
    "\n",
    "  # llm = Anthropic(temperature=0, anthropic_api_key=ANTHROPIC_API_KEY, max_tokens_to_sample = 512)\n",
    "  llm = Bedrock(model_id=\"anthropic.claude-v2\", client=boto3_bedrock, model_kwargs={'max_tokens_to_sample':1000})\n",
    "  \n",
    "  retriever = AmazonKendraRetriever(\n",
    "    index_id=kendra_index_id,\n",
    "    region_name=os.environ.get(\"AWS_DEFAULT_REGION\", None),\n",
    "    top_k=3,\n",
    "    attribute_filter = {\n",
    "        \"EqualsTo\": {      \n",
    "            \"Key\": \"_language_code\",\n",
    "            \"Value\": {\n",
    "                \"StringValue\": \"ko\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "  )\n",
    "  # prompt_template = \"\"\"Human: Use the following pieces of context to provide a concise answer to the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "  prompt_template = \"\"\"Human: Use the following pieces of context to provide a concise answer to the question at the end. If the answer is not in the context, just say \"시스템에 관련 내용을 찾을 수 없습니다.\", don't try to make up an answer.\n",
    "\n",
    "  {context}\n",
    "\n",
    "  Question: {question}\n",
    "  Assistant:\"\"\"\n",
    "\n",
    "  PROMPT = PromptTemplate(\n",
    "      template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    "  )\n",
    "\n",
    "\n",
    "  qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": PROMPT}\n",
    "  )\n",
    "\n",
    "  return qa\n",
    "\n",
    "def run_chain(chain, prompt: str):\n",
    "  return chain({\"query\": prompt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dd7e7e-680b-4471-8b39-890b438ab706",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile app.py\n",
    "\n",
    "import streamlit as st\n",
    "import sys\n",
    "\n",
    "import kendra_claude as claude\n",
    "\n",
    "USER_ICON = \"images/user-icon.png\"\n",
    "AI_ICON = \"images/ai-icon.png\"\n",
    "MAX_HISTORY_LENGTH = 5\n",
    "\n",
    "if 'llm_chain' not in st.session_state:\n",
    "    st.session_state['llm_app'] = claude\n",
    "    st.session_state['llm_chain'] = claude.build_chain()\n",
    "\n",
    "if 'chat_history' not in st.session_state:\n",
    "    st.session_state['chat_history'] = []\n",
    "    \n",
    "if \"chats\" not in st.session_state:\n",
    "    st.session_state.chats = [\n",
    "        {\n",
    "            'id': 0,\n",
    "            'question': '',\n",
    "            'answer': ''\n",
    "        }\n",
    "    ]\n",
    "\n",
    "if \"questions\" not in st.session_state:\n",
    "    st.session_state.questions = []\n",
    "\n",
    "if \"answers\" not in st.session_state:\n",
    "    st.session_state.answers = []\n",
    "\n",
    "if \"input\" not in st.session_state:\n",
    "    st.session_state.input = \"\"\n",
    "\n",
    "\n",
    "st.markdown(\"\"\"\n",
    "        <style>\n",
    "               .block-container {\n",
    "                    padding-top: 32px;\n",
    "                    padding-bottom: 32px;\n",
    "                    padding-left: 0;\n",
    "                    padding-right: 0;\n",
    "                }\n",
    "                .element-container img {\n",
    "                    background-color: #000000;\n",
    "                }\n",
    "\n",
    "                .main-header {\n",
    "                    font-size: 24px;\n",
    "                }\n",
    "        </style>\n",
    "        \"\"\", unsafe_allow_html=True)\n",
    "\n",
    "def write_logo():\n",
    "    col1, col2, col3 = st.columns([5, 1, 5])\n",
    "    with col2:\n",
    "        st.image(AI_ICON, use_column_width='always') \n",
    "\n",
    "\n",
    "def write_top_bar():\n",
    "    col1, col2, col3 = st.columns([1,10,2])\n",
    "    with col1:\n",
    "        st.image(AI_ICON, use_column_width='always')\n",
    "    with col2:\n",
    "        header = f\"Amazon Bedrock이 제공하는 AI 서비스!\"\n",
    "        st.write(f\"<h3 class='main-header'>{header}</h3>\", unsafe_allow_html=True)\n",
    "    with col3:\n",
    "        clear = st.button(\"Clear Chat\")\n",
    "    return clear\n",
    "\n",
    "clear = write_top_bar()\n",
    "\n",
    "if clear:\n",
    "    st.session_state.questions = []\n",
    "    st.session_state.answers = []\n",
    "    st.session_state.input = \"\"\n",
    "    st.session_state[\"chat_history\"] = []\n",
    "\n",
    "def handle_input():\n",
    "    input = st.session_state.input\n",
    "    question_with_id = {\n",
    "        'question': input,\n",
    "        'id': len(st.session_state.questions)\n",
    "    }\n",
    "    st.session_state.questions.append(question_with_id)\n",
    "\n",
    "    chat_history = st.session_state[\"chat_history\"]\n",
    "    if len(chat_history) == MAX_HISTORY_LENGTH:\n",
    "        chat_history = chat_history[:-1]\n",
    "\n",
    "    llm_chain = st.session_state['llm_chain']\n",
    "    chain = st.session_state['llm_app']\n",
    "    result = chain.run_chain(llm_chain, input)\n",
    "    answer = result['result']\n",
    "    chat_history.append((input, answer))\n",
    "    \n",
    "    document_list = []\n",
    "    if 'source_documents' in result:\n",
    "        for d in result['source_documents']:\n",
    "            if not (d.metadata['source'] in document_list):\n",
    "                document_list.append((d.metadata['source']))\n",
    "\n",
    "    st.session_state.answers.append({\n",
    "        'answer': result,\n",
    "        'sources': document_list,\n",
    "        'id': len(st.session_state.questions)\n",
    "    })\n",
    "    st.session_state.input = \"\"\n",
    "\n",
    "def write_user_message(md):\n",
    "    col1, col2 = st.columns([1,12])\n",
    "    \n",
    "    with col1:\n",
    "        st.image(USER_ICON, use_column_width='always')\n",
    "    with col2:\n",
    "        st.warning(md['question'])\n",
    "\n",
    "\n",
    "def render_result(result):\n",
    "    answer, sources = st.tabs(['Answer', 'Sources'])\n",
    "    with answer:\n",
    "        render_answer(result['answer'])\n",
    "    with sources:\n",
    "        if 'source_documents' in result:\n",
    "            render_sources(result['source_documents'])\n",
    "        else:\n",
    "            render_sources([])\n",
    "\n",
    "def render_answer(answer):\n",
    "    col1, col2 = st.columns([1,12])\n",
    "    with col1:\n",
    "        st.image(AI_ICON, use_column_width='always')\n",
    "    with col2:\n",
    "        st.info(answer['result'])\n",
    "\n",
    "def render_sources(sources):\n",
    "    col1, col2 = st.columns([1,12])\n",
    "    with col2:\n",
    "        with st.expander(\"Sources\"):\n",
    "            for s in sources:\n",
    "                st.write(s)\n",
    "\n",
    "    \n",
    "#Each answer will have context of the question asked in order to associate the provided feedback with the respective question\n",
    "def write_chat_message(md, q):\n",
    "    chat = st.container()\n",
    "    with chat:\n",
    "        render_answer(md['answer'])\n",
    "        render_sources(md['sources'])\n",
    "    \n",
    "        \n",
    "with st.container():\n",
    "  for (q, a) in zip(st.session_state.questions, st.session_state.answers):\n",
    "    write_user_message(q)\n",
    "    write_chat_message(a, q)\n",
    "\n",
    "st.markdown('---')\n",
    "input = st.text_input(\"질문을 해주세요!\", key=\"input\", on_change=handle_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d5a5d6-a557-4e2a-a404-8f0f5efe2201",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile requirements.txt\n",
    "\n",
    "boto3==1.28.64\n",
    "streamlit==1.20.0\n",
    "langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e8d804-f5d0-4fb5-80a5-93bd69a54da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile setup.sh\n",
    "\n",
    "pip install --no-cache-dir -r requirements.txt\n",
    "sudo yum install -y iproute\n",
    "sudo yum install -y jq\n",
    "sudo yum install -y lsof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a74374-6a63-404e-9501-c34dff704549",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile run.sh\n",
    "\n",
    "#!/bin/sh\n",
    "CURRENTDATE=`date +\"%Y-%m-%d %T\"`\n",
    "RED='\\033[0;31m'\n",
    "CYAN='\\033[1;36m'\n",
    "GREEN='\\033[1;32m'\n",
    "NC='\\033[0m'\n",
    "S3_PATH=$1\n",
    "\n",
    "# Run the Streamlit app and save the output to \"temp.txt\"\n",
    "streamlit run app.py > temp.txt & \n",
    "\n",
    "# Read the text file using cat\n",
    "echo \"Getting the URL to view your Streamlit app in the browser\"\n",
    "\n",
    "# Extract the last four digits of the port number from the Network URL\n",
    "sleep 5\n",
    "PORT=$(grep \"Network URL\" temp.txt | awk -F':' '{print $NF}' | awk '{print $1}' | tail -c 5)\n",
    "echo -e \"${CYAN}${CURRENTDATE}: [INFO]:${NC} Port Number ${PORT}\" \n",
    "\n",
    "\n",
    "\n",
    "# Get Studio domain information\n",
    "DOMAIN_ID=$(jq .DomainId /opt/ml/metadata/resource-metadata.json || exit 1)\n",
    "RESOURCE_NAME=$(jq .ResourceName /opt/ml/metadata/resource-metadata.json || exit 1)\n",
    "RESOURCE_ARN=$(jq .ResourceArn /opt/ml/metadata/resource-metadata.json || exit 1)\n",
    "\n",
    "# Remove quotes from string\n",
    "DOMAIN_ID=`sed -e 's/^\"//' -e 's/\"$//' <<< \"$DOMAIN_ID\"`\n",
    "RESOURCE_NAME=`sed -e 's/^\"//' -e 's/\"$//' <<< \"$RESOURCE_NAME\"`\n",
    "RESOURCE_ARN=`sed -e 's/^\"//' -e 's/\"$//' <<< \"$RESOURCE_ARN\"`\n",
    "RESOURCE_ARN_ARRAY=($(echo \"$RESOURCE_ARN\" | tr ':' '\\n'))\n",
    "\n",
    "# Get Studio domain region\n",
    "REGION=$(echo \"${RESOURCE_ARN_ARRAY[3]}\")\n",
    "\n",
    "# Check if it's Collaborative Space\n",
    "SPACE_NAME=$(jq .SpaceName /opt/ml/metadata/resource-metadata.json || exit 1)\n",
    "\n",
    "# if it's not a collaborative space \n",
    "if [ -z \"$SPACE_NAME\" ] || [ $SPACE_NAME == \"null\" ] ;\n",
    "then\n",
    "    # If it's a user-profile access\n",
    "    echo -e \"${CYAN}${CURRENTDATE}: [INFO]:${NC} Domain Id ${DOMAIN_ID}\"\n",
    "    STUDIO_URL=\"https://${DOMAIN_ID}.studio.${REGION}.sagemaker.aws\"\n",
    "    \n",
    "# It is a collaborative space\n",
    "else\n",
    "\n",
    "    SEM=true\n",
    "    SPACE_ID=\n",
    "\n",
    "    # Check if Space Id was previously configured\n",
    "    if [ -f /tmp/space-metadata.json ]; then\n",
    "        SAVED_SPACE_ID=$(jq .SpaceId /tmp/space-metadata.json || exit 1)\n",
    "        SAVED_SPACE_ID=`sed -e 's/^\"//' -e 's/\"$//' <<< \"$SAVED_SPACE_ID\"`\n",
    "\n",
    "        if [ -z \"$SAVED_SPACE_ID\" ] || [ $SAVED_SPACE_ID == \"null\" ]; then\n",
    "            ASK_INPUT=true\n",
    "        else\n",
    "            ASK_INPUT=false\n",
    "        fi\n",
    "    else\n",
    "        ASK_INPUT=true\n",
    "    fi\n",
    "\n",
    "    # If Space Id is not available, ask for it\n",
    "    while [[ $SPACE_ID = \"\" ]] ; do\n",
    "        # If Space Id already configured, skeep the ask\n",
    "        if [ \"$ASK_INPUT\" = true ]; then\n",
    "            echo -e \"${CYAN}${CURRENTDATE}: [INFO]:${NC} Please insert the Space Id from your url. e.g. https://${GREEN}<SPACE_ID>${NC}.studio.${REGION}.sagemaker.aws/jupyter/default/lab\"\n",
    "            read SPACE_ID\n",
    "            SEM=true\n",
    "        else\n",
    "            SPACE_ID=$SAVED_SPACE_ID\n",
    "        fi\n",
    "\n",
    "        if ! [ -z \"$SPACE_ID\" ] && ! [ $SPACE_ID == \"null\" ] ;\n",
    "        then\n",
    "            while $SEM; do\n",
    "                echo \"${SPACE_ID}\"\n",
    "                read -p \"Should this be used as Space Id? (y/N) \" yn\n",
    "                case $yn in\n",
    "                    [Yy]* )\n",
    "                        echo -e \"${CYAN}${CURRENTDATE}: [INFO]:${NC} Domain Id ${DOMAIN_ID}\"\n",
    "                        echo -e \"${CYAN}${CURRENTDATE}: [INFO]:${NC} Space Id ${SPACE_ID}\"\n",
    "\n",
    "                        jq -n --arg space_id $SPACE_ID '{\"SpaceId\":$space_id}' > /tmp/space-metadata.json\n",
    "\n",
    "                        STUDIO_URL=\"https://${SPACE_ID}.studio.${REGION}.sagemaker.aws\"\n",
    "\n",
    "                        SEM=false\n",
    "                        ;;\n",
    "                    [Nn]* ) \n",
    "                        SPACE_ID=\n",
    "                        ASK_INPUT=true\n",
    "                        SEM=false\n",
    "                        ;;\n",
    "                    * ) echo \"Please answer yes or no.\";;\n",
    "                esac\n",
    "            done\n",
    "        fi\n",
    "    done\n",
    "fi\n",
    "\n",
    "echo -e \"${CYAN}${CURRENTDATE}: [INFO]:${NC} Studio Url ${STUDIO_URL}\"\n",
    "\n",
    "\n",
    "link=\"${STUDIO_URL}/jupyter/${RESOURCE_NAME}/proxy/${PORT}/\"\n",
    "\n",
    "echo -e \"${CYAN}${CURRENTDATE}: [INFO]:${NC} Starting Streamlit App\"\n",
    "echo -e \"${CYAN}${CURRENTDATE}: [INFO]: ${GREEN}${link}${NC}\"\n",
    "\n",
    "exit 0\n",
    "fi"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
