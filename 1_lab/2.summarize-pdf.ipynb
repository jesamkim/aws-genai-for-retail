{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d23c246-5224-4001-8226-9df202362c43",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 베드락을 이용하여 자료 요약하기\n",
    "\n",
    "> *이 노트북은 SageMaker Studio*의 `Data Science 3.0` 커널과 잘 작동해야 합니다.\n",
    "\n",
    "## 소개\n",
    "\n",
    "이 노트북에서는 리테일 고객이 크기가 큰 문서를 요약하는 방법을 보여드리겠습니다.대용량 문서로 작업할 때 입력 텍스트가 모델 컨텍스트 길이에 맞지 않거나, 모델이 대용량 문서를 인식하지 못하거나, 메모리 부족 오류 등으로 인해 몇 가지 문제에 직면할 수 있습니다. 이러한 문제를 해결하기 위해 청킹 및 연쇄 프롬프트 개념을 기반으로 하는 아키텍처를 보여드리겠습니다. 이 아키텍처는 언어 모델로 구동되는 애플리케이션을 개발하는 데 널리 사용되는 프레임워크인 LangChain을 활용합니다.\n",
    "\n",
    "[LangChain](https://python.langchain.com/docs/get_started/introduction.html)은 언어 모델로 구동되는 애플리케이션을 개발하기 위한 프레임워크입니다. 이 프레임워크의 핵심 측면을 통해 다양한 구성 요소를 연결하여 고급 사용 사례를 만들어 대규모 언어 모델을 보강할 수 있습니다.\n",
    "\n",
    "\n",
    "**참고:** *이 노트북은 AWS 환경 내부 또는 외부에서 실행할 수 있습니다*.\n",
    "\n",
    "#### 컨텍스트\n",
    "\n",
    "이 노트북에서는 LangChain 프레임워크 내에서 Amazon Bedrock과 통합하여 사용는 방법과 PromptTemplate의 도움으로 텍스트를 생성하는 데 어떻게 사용될 수 있는지 살펴보겠습니다.\n",
    "\n",
    "#### 패턴\n",
    "\n",
    "![bedrock_langchian_image](./image/bedrock_summ.png)\n",
    "\n",
    "이 아키텍처에서는\n",
    "1. 큰 문서(또는 작은 문서를 추가한 거대한 파일)가 로드됩니다.\n",
    "2. Langchain 유틸리티를 사용하여 여러 개의 작은 청크로 분할(청킹)합니다.\n",
    "3. 첫 번째 청크가 모델로 전송되고, 모델은 해당 요약을 반환합니다.\n",
    "4. 랭체인은 다음 청크를 가져와서 반환된 요약에 추가하고 결합된 텍스트를 모델에 새 요청으로 보냅니다; 모든 청크가 처리될 때까지 이 과정이 반복됩니다.\n",
    "5. 결국, 전체 콘텐츠를 기반으로 한 최종 요약이 생성됩니다.\n",
    "\n",
    "#### 사용사례\n",
    "\n",
    "이 접근 방식은 통화 녹취록, 회의 녹취록, 책, 기사, 블로그 게시물 및 상품/서비스 관련 콘텐츠를 요약하는 데 사용할 수 있습니다.\n",
    "\n",
    "#### 페르소나\n",
    "\n",
    "리테일 회사인 애니컴퍼니의 제품 담당 매니저인 \"김소매\"는 최근 등록된 제품들에 대한 고객들의 리뷰를 확인하고 있습니다. 수백 개의 리뷰를 요약해서 몇 줄로 정리하여 '대표리뷰'로 등록을 하려고 하는데요, 하루에도 한 제품 당 수십개 이상 올라오는 리뷰를 매번 다 읽어 보기는 어렵습니다. 또한 시간이 경과하면서 바뀌는 고객의 리뷰를 파악하기도 쉽지 않습니다. 이에,대용량의 문서를 요약하여 보여 주기 위헤 LLM의 도움이 필요합니다.\n",
    "\n",
    "\n",
    "#### 구현 방법\n",
    "\n",
    "이 사용 사례를 보여주기 위해 이 노트북에서는 고객의 이전 제품 설명을 기반으로 신규 제품 설명을 생성하는 방법을 보여드리며, Boto3 클라이언트와 함께 Amazon Bedrock API를 사용하는 Anthropic Claude 모델을 사용하겠습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc1d77e-0bc5-4439-9d3f-cebb5a3be4b7",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "이 노트북의 나머지 부분을 실행하기 전에 아래 셀을 실행하여 (필요한 라이브러리가 설치되어 있는지 확인하고) 베드락에 연결해야 합니다.\n",
    "\n",
    "우선 사전에 설치가 필요한 패키지들을 설치하세요. 그 이후에 셋업에 필요한 라이브러리들을 설치합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8360b43e-73e8-4fb5-9e44-a2941fd2a3d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r ./dependencies/requirements.txt > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "139779bc-6e31-45be-ad89-594b18200a84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = \"us-east-1\"  # E.g. \"us-east-1\"\n",
    "os.environ[\"BEDROCK_ENDPOINT_URL\"] = \"https://bedrock-runtime.us-east-1.amazonaws.com\"  # E.g. \"https://...\"\n",
    "\n",
    "session = boto3.Session(\n",
    "    profile_name=os.environ.get(\"AWS_PROFILE\")\n",
    ") # sets the profile name to use for AWS credentials\n",
    "\n",
    "bedrock = session.client(\n",
    "    service_name='bedrock-runtime', # creates a Bedrock client\n",
    "    region_name=os.environ.get(\"AWS_DEFAULT_REGION\"),\n",
    "    endpoint_url=os.environ.get(\"BEDROCK_ENDPOINT_URL\")\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba689a6-ea22-498f-ae1b-36dc2e676fe4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 베드락 LLM 모델 호출하기\n",
    "\n",
    "LLM에서 Bedrock 클래스의 인스턴스를 생성하는 것으로 시작하겠습니다. 여기에는 Amazon Bedrock에서 사용할 수 있는 모델의 ARN인 model_id가 필요합니다.\n",
    "\n",
    "선택적으로 이전에 생성한 boto3 클라이언트를 전달할 수 있으며, `temperature`, `top_p`, `max_tokens_to_sample` 또는 `stop_sequences`와 같은 매개 변수를 보유할 수 있는 일부 `model_kwargs`도 전달할 수 있습니다(매개 변수에 대한 자세한 내용은 Amazon Bedrock 콘솔에서 살펴볼 수 있습니다).\n",
    "\n",
    "Amazon Bedrock에서 사용 가능한 텍스트 생성 모델 ID에 대한 [설명서](https://docs.aws.amazon.com/ko_kr/bedrock/latest/userguide/model-ids-arns.html)를 확인하세요.\n",
    "\n",
    "모델마다 지원하는 `model_kwargs`가 다르다는 점에 유의하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37deab32-7597-4233-a963-1b3628932b28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.llms.bedrock import Bedrock\n",
    "\n",
    "model_kwargs = {'max_tokens_to_sample':8000, \n",
    "                \"temperature\":0,\n",
    "                \"top_k\":250,\n",
    "                \"top_p\":1,\n",
    "                \"stop_sequences\": [\"\\n\\nHuman:\"]\n",
    "                }\n",
    "\n",
    "llm = Bedrock(model_id = \"anthropic.claude-instant-v1\",\n",
    "#llm = Bedrock(model_id = \"anthropic.claude-v2\",\n",
    "                    client = bedrock, \n",
    "                    model_kwargs = model_kwargs \n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4419d8a-5f94-499a-b6e3-4507d52939ba",
   "metadata": {},
   "source": [
    "PDF 문서를 로드한 후에, 긴 문서를 청킹(chunking)합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e9db2c3-88eb-497c-8a91-ef46423ec337",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "\n",
    "pdf_path = \"./2022-Shareholder-Letter-ko.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(file_path=pdf_path)\n",
    "documents = loader.load()\n",
    "        \n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\"], chunk_size=4000, chunk_overlap=100 \n",
    ")\n",
    "    \n",
    "docs = text_splitter.split_documents(documents=documents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe53efd-ff4b-4d70-8442-d02089df7b1a",
   "metadata": {},
   "source": [
    "## MAP-REDUCE \n",
    "\n",
    "'map_reduce' 체인은 큰 문서를 관리하기 쉬운 작은 덩어리로 분할하여 문서 처리를 처리하도록 설계되었습니다. 이 체인은 각 조각에 초기 프롬프트를 사용하여 문서의 특정 섹션을 기반으로 요약 또는 답변을 생성합니다. 또한 MapReduceDocumentsChain은 생성된 출력을 가져와 다른 프롬프트를 사용하여 결합하여 전체 문서에 대한 포괄적이고 일관된 요약 또는 답변을 생성합니다. load_summarize_chain 함수를 사용하여 'map_reduce' 체인을 설정하고 출력 요약을 얻습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36784970-0d2b-4520-abec-26ef66b6c2bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MapReduceDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mCEO로서 두 번째 연례 주주 서한을 작성하기 위해 자리에 앉았을 때 저는 Amazon의 앞날에 대해 낙관적이고 활력을 얻었습니다. 2022년은 최근 기억에 있어 어려운 거시경제적 해 중 하나이고 우리 자체의 운영상의 어려움에도 불구하고 우리는 여전히 수요를 늘릴 방법을 찾았습니다(팬데믹 전반기에 경험한 전례 없는 성장에 더해). 우리는 장단기적으로 고객 경험을 의미 있게 개선하기 위해 대규모 사업을 혁신했습니다. 그리고 고객, 주주 및 직원을 위해 Amazon의 미래를 바꿀 수 있다고 믿는 장기 투자를 계속 유지하면서 투자 결정과 앞으로 나아갈 방법에 중요한 조정을 했습니다.  작년에 이례적인 수의 동시 도전 과제가 있었지만 현실은 유능하고 자금이 충분한 경쟁자가 많은 크고 역동적인 글로벌 시장 부문에서 운영하는 경우(아마존이 모든 비즈니스를 운영하는 조건) 조건이 오랫동안 정체되어 있는 경우는 드뭅니다.  제가 Amazon에 근무한 25년 동안 끊임없는 변화가 있었고 그 중 대부분은 우리가 스스로 시작했습니다. 내가 1997년에 Amazon에 입사했을 때 우리는 1996년에 1,500만 달러의 매출을 올렸고, 도서 전용 소매업체였으며, 제3자 시장이 없었고, 미국 내 주소로만 배송되었습니다. 오늘날 Amazon은 단위 판매의 60%를 차지하고 전 세계 거의 모든 국가의 고객에게 도달하는 활기찬 타사 판매자 에코시스템을 통해 상상할 수 있는 거의 모든 물리적 및 디지털 소매 품목을 판매합니다. 마찬가지로 클라우드에서 일련의 기술 인프라 서비스를 중심으로 비즈니스를 구축하는 것은 AWS를 추구하기 시작한 2003년에는 분명하지 않았으며 2006년 첫 서비스를 출시했을 때도 마찬가지였습니다. 거의 모든 책을 60초 안에 손끝에서 볼 수 있습니다 2007년 Kindle을 출시했을 때 가벼운 디지털 리더에 저장하고 검색할 수 있다는 것은 아직 \"사물\"이 아니었고 Alexa(2014년 출시)와 같이 액세스하는 데 사용할 수 있는 음성 기반 개인 비서도 아니었습니다. 엔터테인먼트, 스마트 홈 제어, 쇼핑 및 모든 종류의 정보 검색.  또한 거시 경제 상황이나 운영 비효율성으로 인해 우리에게 새로운 과제가 제시된 경우도 있었습니다. 예를 들어 2001년 닷컴 폭락 당시 우리는 연휴 기간 동안 재고를 구매하기 위해 신용장을 확보해야 했고 비즈니스의 더 나은 수익성을 제공하기 위해 비용을 합리화해야 했지만 여전히 우리가 노력하고 있던 장기적인 고객 경험과 비즈니스를 우선시했습니다. 빌드(기억한다면, 우리는 실제로 2001년 그 미미한 기간 동안 대부분의 범주에서 가격을 낮췄습니다). 2008-2009년에 모기지 담보 증권 금융 위기로 촉발된 경기 침체를 견디면서 이런 종류의 균형을 다시 보았습니다. 우리는 매장 비즈니스의 비용 구조와 효율성을 관리하기 위해 몇 가지 조치를 취했지만, 주주에게 강력한 수익을 제공하는 실질적인 미래 비즈니스가 될 수 있다고 생각하는 고객 경험에 대한 투자와 이러한 합리화의 균형을 맞췄습니다. 2008년에 AWS는 여전히 상당히 작고 신생 기업이었습니다. 우리는 우리가 무언가를 하고 있다는 것을 알고 있었지만\n",
      "\n",
      "위의 내용을 Korean으로 bullet point 3개로 요약합니다:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m여전히 상당한 자본 투자가 필요했습니다. 회사 안팎에서는 아마존(당시 주로 온라인 소매업체로 알려짐)이 클라우드 컴퓨팅에 많은 투자를 하는 이유에 대해 의문을 제기하는 목소리가 있었습니다. 그러나 우리는 미래에 고객과 아마존을 위해 많은 가치를 창출할 수 있는 특별한 것을 발명하고 있다는 것을 알고 있었습니다. 우리는 잠재적 경쟁자보다 먼저 출발했습니다. 무엇보다 우리는 혁신 속도를 가속화하고 싶었습니다. 우리는 AWS에 계속 투자하기로 장기적인 결정을 내렸습니다. 15년 후 AWS는 이제 신생 기업에서 다국적 기업, 공공 부문 조직에 이르기까지 고객이 기술 인프라를 관리하는 방식을 변화시킨 강력한 수익성을 갖춘 연간 매출 850억 달러 규모의 기업이 되었습니다. 2008-2009년 기간 동안 AWS에 대한 투자를 늦추었다면 Amazon은 다른 회사가 되었을 것입니다.  변화는 항상 가까이에 있습니다. 때로는 적극적으로 초대하고 때로는 그냥 노크합니다. 그러나 그것이 오는 것을 보았을 때, 그것을 받아들여야 합니다. 그리고 장기간에 걸쳐 이를 잘 수행하는 회사는 일반적으로 성공합니다. 나는 우리 팀이 우리 앞에 보이는 변화에 대응하는 방식이 마음에 들기 때문에 우리의 미래 전망에 대해 낙관적입니다.  지난 몇 달 동안 우리는 회사 전체를 비즈니스별로, 발명별로 자세히 살펴보고 각 이니셔티브의 장기적인 잠재력에 대해 충분한 수익, 운영 수입, 무료 현금 흐름, 투자 자본 수익률. 경우에 따라 특정 비즈니스를 폐쇄하게 되었습니다. 예를 들어 우리는 서점 및 4스타 매장과 같은 물리적 매장 개념 추구를 중단하고 Amazon Fabric 및 Amazon Care 노력을 중단했으며 의미 있는 수익을 얻을 수 있는 경로가 보이지 않는 일부 최신 장치에서 전환했습니다. 다른 경우에는 우리가 기대했던 수익을 내지 못하는 일부 프로그램(예: $35 이상의 모든 온라인 식료품 주문에 대한 무료 배송)을 살펴보고 수정했습니다. 우리는 또한 리소스를 어디에 사용할지 우선 순위를 재지정했고, 결국 27,000개의 회사 역할을 제거하는 어려운 결정을 내렸습니다. 전체 비용을 합리화하기 위해 지난 몇 개월 동안 수행한 다른 변경 사항이 많이 있으며 대부분의 리더십 팀과 마찬가지로 비즈니스에서 보고 있는 사항을 계속 평가하고 적응적으로 진행할 것입니다.  우리는 또한 팀으로 어떻게 협력하고 있는지 열심히 살펴보았고 회사 직원들에게 5월부터 일주일에 최소 3일은 사무실로 돌아올 것을 요청했습니다. 팬데믹 기간 동안 우리 직원들은 집에서 일하기 위해 집결했으며 예상치 못한 상황에 대처하기 위해 가능한 모든 일을 했습니다. 그것은 인상적이었고 저는 우리의 집단적 팀이 고객, 지역 사회 및 비즈니스에 대한 전례 없는 도전을 극복하기 위해 함께 모인 방식이 자랑스럽습니다. 그러나 우리는 이것이 최선의 장기적 접근 방식이라고 생각하지 않습니다. 우리는 함께 일하고 직접 서로에게서 배울 때 협업과 발명이 더 쉽고 효과적이라는 것을 확신하게 되었습니다. 서로의 아이디어에 대한 에너지와 반복은 더 자유롭게 발생하며 최고의 Amazon 발명품 중 다수는 사람들이 회의 후 뒤에 남아 화이트보드에서\n",
      "\n",
      "위의 내용을 Korean으로 bullet point 3개로 요약합니다:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m아이디어를 검토하거나 회의에서 돌아오는 길에 대화를 계속하면서 획기적인 순간을 맞이했습니다. , 또는 다른 생각으로 그날 늦게 팀원의 사무실에 들르는 것. 발명은 종종 지저분합니다. 그것은 방황하고 구불 구불하고 마리 네이드합니다. 뜻밖의 상호 작용이 도움이 되며, 가상으로 하는 것보다 직접 만나는 것이 더 많습니다. 또한 우리가 대부분의 시간을 함께 사무실에 있고 동료들에게 둘러싸여 있을 때 우리 문화를 배우고, 모델링하고, 연습하고, 강화하는 것이 훨씬 더 쉽습니다. 혁신과 우리 고유의 문화는 회사로서 처음 29년 동안 매우 중요했으며 다음 29년에도 마찬가지로 그렇게 될 것으로 기대합니다.  우리가 계속해서 해결해야 할 중요한 문제는 매장 주문 처리 네트워크에서 서비스를 제공하는 데 드는 비용(예: Amazon에서 고객에게 제품을 제공하는 비용)이 증가하는 것입니다. 비용 및 배송 속도.  팬데믹 초기에는 많은 오프라인 매장이 문을 닫았고, 우리 소비자 비즈니스는 놀라운 속도로 성장하여 연간 매출이 2019년 2,450억 달러에서 2022년 4,340억 달러로 증가했습니다. 이는 주문 처리 센터 공간을 두 배로 늘려야 함을 의미했습니다. 지난 25년 동안 우리가 구축한 운송 네트워크를 현재 UPS 크기의 라스트 마일 운송 네트워크 구축을 크게 가속화했습니다(항목이 장거리를 통과해야 할 때 효율성과 속도를 지원하기 위한 새로운 분류 센터 네트워크 포함). 약 2년의 시간 동안. 이것은 쉬운 일이 아니었고 수십만 명의 아마존 사람들이 이것을 실현하기 위해 매우 열심히 일했습니다. 그러나 이러한 변화의 속도와 규모로 인해 의도한 생산성을 얻기 위해서는 많은 최적화가 필요했습니다. 지난 몇 달 동안 우리는 주문 처리 센터 및 운송 네트워크의 모든 프로세스 경로를 면밀히 조사하고 수십 가지 프로세스 및 메커니즘을 재설계하여 지난 몇 분기 동안 꾸준한 생산성 향상과 비용 절감을 가져왔습니다. 해야 할 일이 더 많지만 우리의 궤적과 우리 앞에 있는 의미 있는 상승세에 만족합니다.  우리는 또한 앞으로 수년 동안 더 낮은 비용과 더 빠른 속도를 제공할 수 있도록 더 큰 구조적 변화를 만들기 위해 이 기회를 잡았습니다. 좋은 예는 미국 주문 처리 네트워크가 어떻게 구성되어 있는지 재평가하는 것입니다. 최근까지 아마존은 미국 전역에 퍼져 있는 주문 처리 센터의 재고를 분배하는 하나의 미국 전국 주문 처리 네트워크를 운영했습니다. 지역 주문 처리 센터에 고객이 주문한 제품이 없으면 결국 다른 지역에서 배송하게 되므로 더 많은 비용이 들고 배송 시간이 늘어납니다. 이 문제는 주문 처리 네트워크가 지난 몇 년 동안 수백 개의 추가 노드로 확장되어 더 많은 위치에 재고를 분배하고 주문 처리 센터와 배송 스테이션 노드를 효율적으로 연결하는 복잡성이 증가함에 따라 더욱 두드러졌습니다. 작년에 우리는 재고 배치 전략을 재설계하고 더 큰 주문 처리 센터 공간을 활용하여 전국 주문 처리 네트워크에서 지역화된 네트워크 모델로 이동하기 시작했습니다. 우리는 더 작은 지리적 영역에 8개의 상호 연결된 지역을 만들기 위해\n",
      "\n",
      "위의 내용을 Korean으로 bullet point 3개로 요약합니다:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m상당한 내부 변경(예: 배치 및 물류 소프트웨어, 프로세스, 물리적 운영)을 수행했습니다. 이러한 각 지역은 대부분 자급자족 방식으로 운영할 수 있는 광범위하고 적절한 선택권을 가지고 있으며 필요할 때 여전히 전국적으로 배송할 수 있습니다. 가장 의미 있고 힘든 작업 중 일부는 이 많은 양의 인프라 간의 연결을 최적화하는 데 있었습니다. 또한 적시에 올바른 지역에 올바른 재고를 보유할 수 있도록 국가의 여러 지역에 있는 고객이 필요로 하는 것이 무엇인지 더 잘 예측하기 위해 고급 기계 학습 알고리즘을 지속적으로 개선하고 있습니다. 최근에 이 지역 출시를 완료했으며 초기 결과가 마음에 듭니다. 이동 거리가 짧다는 것은 서비스 비용이 낮아지고 환경에 미치는 영향이 줄어들며 고객이 주문을 더 빨리 받는 것을 의미합니다. 후자의 경우 더 많은 익일 배송 및 당일 배송을 보게 되어 기쁩니다. 2023년에는 프라임 배송 속도가 가장 빨라질 것입니다. 전반적으로 우리는 비용 절감, 배송 감소 계획에 대해 확신을 가지고 있습니다. 건전한 운영 마진으로 의미 있게 더 큰 소매 사업을 구축하십시오.  AWS는 연간 850억 달러의 수익을 내고 있으며 아직 채택 곡선 초기 단계에 있지만 장기적으로 고객에게 가장 중요한 것에 집중하는 것이 중요한 시점에 있습니다. 2022년에 620억 달러의 수익 기반으로 전년 대비 29%(\"YoY\") 성장했음에도 불구하고 AWS는 기업들이 현재의 어려운 거시 경제 상황을 고려할 때 지출에 더욱 신중을 기하고 있기 때문에 단기적인 역풍에 직면해 있습니다. 일부 회사는 이 어려운 시기에 고객으로부터 최대한 많은 돈을 뽑아낼 수 있는 방법에 집착할 수 있지만 장기적으로 고객이 원하는 것도 고객을 위한 최선도 아니므로 우리는 다른 방식을 취하고 있습니다. AWS와 클라우드 컴퓨팅의 많은 이점 중 하나는 비즈니스가 성장하면 원활하게 확장할 수 있다는 것입니다. 반대로 비즈니스 계약이 체결되면 해당 용량을 반환하고 비용 지불을 중단하도록 선택할 수 있습니다. 이러한 탄력성은 클라우드에 고유하며 자체 온프레미스 데이터 센터, 서버 및 네트워킹 장비에 이미 값비싼 자본 투자를 한 경우에는 존재하지 않습니다. AWS에서는 모든 비즈니스와 마찬가지로 한 분기 또는 1년 동안 최적화하려고 하지 않습니다. 우리는 우리 모두보다 오래 지속되는 고객 관계(및 비즈니스)를 구축하기 위해 노력하고 있습니다. 그 결과 AWS 영업 및 지원 팀은 고객이 이 불확실한 경제를 더 잘 헤쳐나갈 수 있도록 AWS 지출을 최적화하는 데 많은 시간을 할애하고 있습니다. 이러한 AWS 고객 중 다수는 비용 최적화만큼 비용 절감이 아니라 리소스를 가져와 계획 중인 새롭고 독창적인 새로운 고객 경험에 적용할 수 있다고 말합니다. 고객은 이러한 고객 중심의 장기적인 접근 방식을 높이 평가했으며 고객과 AWS 모두에게 좋은 징조가 될 것이라고 생각합니다.  이러한 단기 역풍이 우리의 성장률을 약화시키는 동안 우리는 AWS에서 볼 수 있는 많은 기본 사항을 좋아합니다. 우리의 새로운 고객 파이프라인은 활성 마이그레이션과 마찬가지로 강력합니다. 많은 기업이 이와 같은 비연속 기간을 사용하여 뒤로 물러나 전략적으로 변경하려는 사항을 결정합니다. 자체 인프라 관리를 거부하고 민첩성, 혁신, 비용 절감 효과를 누리기 위해\n",
      "\n",
      "위의 내용을 Korean으로 bullet point 3개로 요약합니다:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mAWS로 이전하는 것을 선호하는 기업이 점점 더 많아지고 있습니다. 효율성 및 보안 이점. 그리고 고객에게 가장 중요한 것은 AWS가 계속해서 새로운 기능을 신속하게 제공하고(2022년에 출시된 3,300개 이상의 새로운 기능 및 서비스) 가능한 것을 변화시키는 장기적인 발명에 투자한다는 것입니다.  칩 개발이 좋은 예입니다. 작년 편지에서 저는 Graviton이라는 범용 CPU 프로세서에 대한 투자에 대해 언급했습니다. Graviton2 기반 컴퓨팅 인스턴스는 비슷한 최신 세대 x86 기반 인스턴스보다 최대 40% 더 나은 가격 대비 성능을 제공합니다. 2022년에는 Graviton2 프로세서보다 25% 향상된 성능을 제공하는 Graviton3 칩을 제공했습니다. 또한 기계 학습 채택이 지속적으로 가속화됨에 따라 고객은 저렴한 GPU(기계 학습에 가장 일반적으로 사용되는 칩)를 원했습니다. AWS는 몇 년 전부터 기계 학습 훈련 및 추론을 위한 이러한 특수 칩에 투자하기 시작했습니다(추론은 기계 학습 모델이 제공하는 예측 또는 답변입니다). 우리는 2022년에 첫 번째 교육용 칩(\"Trainium\")을 제공했습니다. 가장 일반적인 기계 학습 모델의 경우 Trainium 기반 인스턴스는 GPU 기반 인스턴스보다 최대 70% 더 저렴한 비용으로 최대 140% 더 빠릅니다. 대부분의 회사는 아직 교육 단계에 있지만 대규모 생산으로 전환되는 모델을 개발함에 따라 모델은 주기적으로 교육되는 반면 추론은 관련 응용 프로그램으로 항상 발생하기 때문에 대부분의 비용이 추론에 있음을 알게 될 것입니다. 행사중입니다. 우리는 2019년에 첫 번째 추론 칩(\"InferenTa\")을 출시했으며 Amazon과 같은 회사는 이미 1억 달러 이상의 자본 비용을 절감했습니다. 방금 출시된 InferenTa2 칩은 첫 번째 InferenTa 프로세서보다 최대 4배 더 높은 처리량과 10배 더 짧은 대기 시간을 제공합니다. 기계 학습의 엄청난 성장으로 인해 고객은 훨씬 저렴한 비용으로 AWS의 교육 및 추론 칩을 사용하여 훨씬 더 많은 작업을 수행할 수 있습니다. 여기서 혁신이 거의 완료되지 않았으며 이 장기 투자는 고객과 AWS 모두에게 유익한 것으로 입증되어야 합니다. AWS는 아직 진화의 초기 단계에 있으며 향후 10년 동안 비정상적으로 성장할 가능성이 있습니다.  마찬가지로 높은 잠재력을 지닌 Amazon의 광고 비즈니스는 브랜드에 고유한 효과를 발휘하며, 이는 계속해서 빠른 속도로 성장하는 이유 중 하나입니다. 선반 공간, 엔드 캡, 원형 배치를 판매하는 물리적 소매업체의 광고 사업과 유사하게, 당사가 후원하는 제품 및 브랜드 제품은 10년 이상 아마존 쇼핑 경험의 필수적인 부분이었습니다. 그러나 실제 소매업체와 달리 Amazon은 쇼핑 행동에 대해 알고 있는 것과 기계 학습 알고리즘에 대한 우리의 매우 깊은 투자를 고려할 때 이러한 후원 제품을 고객이 검색하는 것과 관련이 있도록 조정할 수 있습니다. 이는 고객에게 더 유용한 광고로 이어집니다. 결과적으로 브랜드에 더 나은 성능을 제공합니다. 이것이 우리의 광고 수익이 지난 2022년 4분기에 23% YoY , 310억 달러 수익 기반에서 2022년에 전체적으로 25% YoY 성장을 지속한 이유 중 하나입니다. 몇 분기.\n",
      "\n",
      "위의 내용을 Korean으로 bullet point 3개로 요약합니다:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m우리는 광고주가 자신의 브랜드를 구축할 수 있는 최고의 장소가 되기 위해 노력합니다. 우리는 그 임무를 달성하는 데 도움이 될 장단기 기회를 가지고 있습니다. 우리는 광고 선택 알고리즘을 계속 연마하기 위해 기계 학습에 많은 투자를 계속하고 있습니다. 지난 몇 년 동안 우리는 포괄적이고 유연하며 내구성 있는 계획 및 측정 솔루션을 구축하는 데 투자하여 마케터에게 광고 효과에 대한 더 큰 통찰력을 제공했습니다. 예를 들어 Amazon MarkeTng Cloud(\"AMC\")가 있습니다. AMC는 광고주가 개인정보를 보호하는 방식으로 자사 및 제3자 입력 범위에서 맞춤 잠재고객 및 캠페인 분석을 실행하여 광고 및 비즈니스 통찰력을 생성하여 광범위한 마케팅 및 판매 전략. 광고 팀과 AWS 팀은 기업이 데이터를 AWS에 저장하고, Amazon 및 기타 타사 데이터 소스와 함께 AMC에서 안전하게 운영하고, AWS에서 분석을 수행하고, Amazon 또는 타사 게시자에서 광고를 활성화할 수 있는 옵션을 갖도록 협력했습니다. Amazon 수요 측 플랫폼을 통해. 고객은 이러한 공동 기능을 정말 좋아합니다. 우리는 또한 광고를 비디오, 라이브 스포츠, 오디오 및 식료품 제품에 신중하게 통합할 미래의 기회를 봅니다. 우리는 브랜드가 적절한 고객과 독특하게 소통하고 비즈니스의 이 부분을 성장시킬 수 있도록 계속 열심히 노력할 것입니다.  격동의 시기에 기존 대기업에만 집중하고 다양한 차원에서 고객을 지원하는 지속 가능하고 오래 지속되며 성장하는 회사를 구축하려는 유혹이 있지만 장기적인 고객 경험을 개발하고 작업하는 것을 멈출 수는 없습니다. 고객과 회사에 의미 있는 영향을 미칠 수 있습니다.  새로운 투자 기회를 모색할 때 다음과 같은 몇 가지 질문을 스스로에게 던집니다.  우리가 성공한다면 규모가 크고 투자 자본에 대한 합리적인 수익을 낼 수 있을까요? 오늘 기회가 잘 제공되고 있습니까? 차별화된 접근 방식이 있습니까? 그리고, 우리는 그 분야에 대한 역량을 가지고 있습니까? 그렇지 않다면 빨리 획득할 수 있습니까? 이러한 질문에 대한 답변이 마음에 들면 투자할 것입니다. 이 과정은 간단해 보이는 일부 확장과 일부 사람들이 처음에 추측하지 못한 확장으로 이어졌습니다.  가장 초기의 예는 단순히 책을 판매하는 것에서 음악, 비디오, 전자 제품 및 장난감과 같은 범주를 추가하는 것으로 확장하기로 선택한 경우입니다. 그 당시(1998-1999)에는 보편적인 박수갈채를 받지 못했지만 돌이켜보면 꽤 분명한 것 같습니다.  해외 매장 확장에 대해서도 마찬가지입니다. 2022년에 우리의 국제 소비자 부문은 1,180억 달러의 수익을 창출했습니다. 더 크고 확립된 국제 소비자 비즈니스에서 우리는 거시경제 상황 둔화의 영향을 받을 만큼 충분히 큽니다. 그러나 2019-2021년에는 영국의 30%, 독일의 26%, 일본의 21%(FX 영향 제외)의 복합 연간 성장률(“CAGR”)로 큰 규모에서 놀라운 성장을 보였습니다. 지난 몇\n",
      "\n",
      "위의 내용을 Korean으로 bullet point 3개로 요약합니다:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m년 동안 우리는 인도, 브라질, 멕시코, 호주, 다양한 유럽 국가, 중동 및 아프리카 일부를 포함한 새로운 국제 지역에 투자했습니다. 이 새로운 국가들은 시작하고 확장하기 위해 일정량의 고정 투자를 받지만 우리는 그들의 궤도가 마음에 들고 그들의 성장 패턴은 우리가 북미와 우리가 확립한 국제 지역에서 본 것과 유사합니다. 신흥 국가에는 때때로 우리 사업이 의존하는 일부 인프라와 서비스(예: 결제 방법, 운송 서비스 및 인터넷/통신 인프라)가 부족합니다. 이러한 문제를 해결하기 위해 다양한 파트너와 지속적으로 협력하여 고객에게 솔루션을 제공합니다. 궁극적으로 우리는 더 넓은 지역에 서비스를 제공하기 위한 이러한 투자를 통해 전 세계의 더 많은 고객을 돕고 무료 현금 흐름을 창출하는 더 큰 소비자 비즈니스를 구축할 수 있을 것이라고 믿습니다.  지리적 확장을 넘어 우리는 일부 크고 독특한 제품 소매 시장 부문에 걸쳐 고객 서비스를 확장하기 위해 노력해 왔습니다. 식료품은 미국에서만 평균 8000억 달러 규모의 시장 부문이며, 평균 가구 쇼핑은 주당 3-4회입니다. Amazon은 거의 20년 동안 다소 특이하지만 중요한 식료품 사업을 구축했습니다. 1980년대에 다른 대량 상인들이 식료품 공간에 진입한 방식과 유사하게 우리는 종이 제품, 통조림 및 박스 식품, 사탕 및 스낵, 애완 동물 관리, 건강 및 퍼스널 케어, 뷰티. 그러나 동일한 카테고리에 대해 일반적인 슈퍼마켓의 30K에 비해 300만 개 이상의 항목을 제공합니다. 현재 온라인 배송 서비스 비용을 감안할 때 지금까지 우리는 더 큰 팩 크기에도 초점을 맞췄습니다. 우리는 식료품 사업의 규모와 성장에 만족하지만 오늘날보다 더 많은 고객의 식료품 요구 사항에 부응하고자 합니다. 이를 위해서는 대부분의 식료품 쇼핑이 여전히 물리적 장소에서 발생한다는 점을 감안할 때 더 넓은 물리적 매장 공간이 필요합니다. Whole Foods Market은 40년 전에 자연 및 유기농 전문 식료품점 개념을 개척했습니다. 오늘날 건강하고 지속 가능한 식품에 대한 기준을 지속적으로 높이는 대규모 성장 사업입니다. 지난 1년 동안 우리는 비즈니스에 대한 투자를 계속하면서 수익성을 개선하기 위한 변화도 시도했습니다. Whole Foods는 고무적인 길을 가고 있지만 실제 식료품에 더 큰 영향을 미치려면 광범위하게 확장할 가치가 있다고 생각하는 대량 식료품 형식을 찾아야 합니다. Amazon Fresh는 우리가 몇 년 동안 실험해 온 브랜드이며 Amazon 규모에 적합한 대량 식료품 형식을 식별하고 구축하기 위해 열심히 노력하고 있습니다. 식료품은 Amazon의 큰 성장 기회입니다.  아마존 비즈니스는 우리의 전자상거래 및 물류 역량이 이 대규모 시장 부문을 추구할 수 있는 좋은 위치를 차지하는 투자의 또 다른 예입니다. Amazon Business를 사용하면 기업, 지방 자치 단체 및 조직이 사무용품 및 기타 대량 품목과 같은 제품을 쉽고 저렴하게 조달할 수 있습니다. 경제의 일부 영역이 지난 몇 년 동안 어려움을 겪었지만 아마존 비즈니스는 번창했습니다. 왜? 팀은 선택, 가치 및 편의성을 비즈니스 조달 설정으로 전달하고 고객의 의견을 지속적으로 듣고 고객을 대신하여 혁신한다는 의미를 번역했기 때문입니다. 일부 사람들은 Amazon Business에 대해 들어본 적이 없지만 비즈니스 고객은 Amazon Business를 좋아합니다. Amazon Business는 2015년에\n",
      "\n",
      "위의 내용을 Korean으로 bullet point 3개로 요약합니다:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m시작되었으며 현재 연간 총 매출이 약 350억 달러에 이릅니다. 전 세계 Fortune 100대 기업 중 96개 기업을 포함하여 600만 명 이상의 활성 고객이 Amazon Business의 원스톱 쇼핑, 실시간 분석 및 수억 개의 비즈니스 용품에 대한 광범위한 선택을 즐기고 있습니다. 우리는 지금까지 가능한 것의 극히 일부에 불과하다고 믿으며 비즈니스 고객이 필요로 하고 원한다고 말하는 기능을 계속해서 구축할 계획입니다.  많은 브랜드와 판매자가 아마존 마켓플레이스에서 제품을 성공적으로 판매하고 있지만 자체 소비자 직접 웹사이트를 시작한 많은 브랜드와 판매자도 있습니다. 이러한 판매자의 과제 중 하나는 보기에서 구매로의 전환을 유도하는 것입니다. 우리는 이 문제를 해결하기 위해 Buy with Prime을 개발했습니다. Prime으로 구매하면 타사 브랜드 및 판매자가 자체 웹사이트에서 대규모 Amazon Prime 멤버십에 제품을 제공하고 해당 고객에게 Amazon 계정을 통해 빠른 무료 프라임 배송 및 원활한 결제를 제공할 수 있습니다. Buy with Prime은 Amazon Pay 및 Fulﬁllment by Amazon을 통해 Amazon에서 제품 보관, 피킹, 포장, 배송, 결제 및 모든 반품을 처리하는 등 판매자에게 몇 가지 추가 혜택을 제공합니다. Buy with Prime은 최근 모든 미국 판매자에게 제공되었습니다. 지금까지 Buy with Prime은 타사 쇼핑 사이트에서 구매자 전환을 평균 25% 증가시켰습니다. 가맹점은 더 많은 판매를 전환하고 이러한 배송을 더 쉽게 이행할 수 있다는 사실에 흥분하고 있으며, 프라임 회원은 더 많은 목적지에서 프라임 혜택을 사용할 수 있다는 점에 만족하고 있으며 프라임으로 구매를 통해 더 많은 웹에서 쇼핑 경험을 개선할 수 있습니다.  국제적으로 확장하고, 아직 아마존의 초기 단계인 대규모 소매 시장 부문을 추구하고, 판매자가 자신의 웹사이트에서 보다 효과적으로 판매할 수 있도록 돕기 위해 우리의 고유한 자산을 사용하는 것은 우리에게 어느 정도 자연스러운 확장입니다. 핵심 비즈니스에서 더 멀리 떨어져 있지만 고유한 기회가 있는 투자도 몇 가지 있습니다. 2003년에는 AWS가 전형적인 예였습니다. 2023년에는 Amazon Healthcare와 Kuiper가 잠재적인 아날로그입니다.  의료 분야에서 우리의 초기 노력은 전자 상거래에서 크게 벗어난 것처럼 느껴지지 않는 약국에서 시작되었습니다. 수년 동안 Amazon 고객은 현재 공급자에 대한 불만이 커지면서 언제 온라인 약국을 제공할지 물었습니다. 2020년에 출시된 Amazon Pharmacy는 Prime 회원에게 투명한 가격, 손쉬운 리필 및 비용 절감을 제공하는 풀 서비스 온라인 약국입니다. 비즈니스는 빠르게 성장하고 있으며 혁신을 계속하고 있습니다. 예를 들어 Amazon Pharmacy는 최근 RxPass를 출시했습니다. RxPass는 매월 5달러의 정액 요금으로 Prime 회원이 고혈압, 위산 역류 및 불안과 같은 수십 가지 일반적인 조건에 필요한 적격 처방약을 원하는 만큼 받을 수 있습니다. . 그러나 고객은 Amazon이 비효율적이고 만족스럽지 못한 광범위한 의료 경험에 대한 더 나은 대안을 제공하기를 바라는 강한 열망을 계속 표명했습니다. 우리는 일차 진료가 환자 여정에서 널리 퍼진 첫 번째 중지이기\n",
      "\n",
      "위의 내용을 Korean으로 bullet point 3개로 요약합니다:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m때문에 시작하기로 결정했습니다. 우리는 Amazon Care와 같은 일부 초기 Amazon 실험을 포함하여 기존 환경을 광범위하게 평가하고 연구했습니다. 이 과정에서 우리는 One Medical의 환자 중심 경험이 우리의 미래 사업을 구축하기 위한 훌륭한 기반임을 확인했습니다. 그리고 2022년 7월에 One Medical 인수를 발표했습니다. 고객님들이 원메디컬에 대해 좋아하는 요소가 몇가지 있습니다. 환자가 채팅이나 화상 회의를 통해 의사와 문제를 쉽게 논의할 수 있는 환상적인 디지털 앱이 있습니다. 실제 방문이 필요한 경우 One Medical은 미국 전역의 도시에 사무실을 두고 환자가 당일 또는 익일 약속을 예약할 수 있습니다. One Medical은 각 도시의 전문의와 관계를 맺고 있으며 지역 병원 시스템과 긴밀히 협력하여 전문의를 쉽게 만날 수 있으므로 One Medical 회원은 필요할 때 이러한 리소스에 신속하게 액세스할 수 있습니다. 앞으로 우리는 One Medical과 Amazon이 고객을 위한 1차 진료의 모습을 변화시키기 위해 계속해서 함께 혁신할 것이라고 굳게 믿습니다.  Kuiper는 Amazon이 고객 요구 사항이 높은 영역에서 장기적으로 고객을 위해 혁신한 또 다른 예입니다. Kuiper에 대한 우리의 비전은 현재 없는 전 세계에 고품질 광대역 인터넷 서비스를 제공하는 저궤도 위성 시스템을 만드는 것입니다. 인터넷에 안정적으로 액세스할 수 없는 수억 개의 가정과 기업이 있습니다. 사람들이 온라인 교육 과정을 수강하고, 금융 서비스를 사용하고, 사업을 시작하고, 쇼핑을 하고, 엔터테인먼트를 즐기는 것부터 서비스 범위, 효율성 및 운영을 개선하는 기업 및 정부에 이르기까지 안정적인 연결로 무엇을 할 수 있을지 상상해 보십시오. Kuiper는 접근성뿐만 아니라 경제성도 제공할 것입니다. 우리 팀은 액세스 장벽을 낮출 저비용 안테나(예: 고객 단말기)를 개발했습니다. 우리는 최근 오버헤드를 통과하는 위성과 통신할 새 터미널을 공개했으며 표준 주거용 버전을 개당 $400 미만으로 생산할 수 있을 것으로 기대합니다. 그것들은 작습니다: 11인치 정사각형, 1인치 두께, 마운팅 브래킷을 제외하고 무게는 5파운드 미만이지만 초당 최대 400메가비트의 속도를 제공합니다. 그리고 Amazon에서 설계한 베이스밴드 칩으로 구동됩니다. 우리는 올해 전체 엔드-투-엔드 통신 네트워크를 테스트하기 위해 두 개의 프로토타입 위성을 발사할 준비를 하고 있으며 2024년에는 상용 고객과 함께 베타 테스트를 할 계획입니다. 지금까지 Kuiper에 대해 공유한 내용에 대한 고객 반응은 매우 긍정적이며 Kuiper가 Amazon에 매우 큰 잠재적 기회를 제공한다고 믿습니다. 또한 처음에는 자본 집약적이라는 점에서 AWS와 몇 가지 유사점을 공유하지만 잠재 소비자, 기업 및 정부 고객 기반이 넓고 상당한 수익 및 영업 이익 잠재력이 있으며 기술 및 창의적 능력을 갖춘 회사가 상대적으로 적다는 점에서 AWS와 유사합니다. 그것을 추구하는 투자 가설로.  제가 언급할 마지막 투자 영역은 Amazon이 앞으로 수십 년 동안 모든 비즈니스 영역에서 발명할 수 있도록 설정하는 핵심이며 대규모 언어 모델(\"LLM\") 및 생성 AI입니다. 머신 러닝은 수십 년 동안 유망한 기술이었지만 기업에서 널리 사용되기 시작한 것은 불과 5~10년 전입니다. 이러한\n",
      "\n",
      "위의 내용을 Korean으로 bullet point 3개로 요약합니다:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m변화는 그 어느 때보다 낮은 가격으로 더 많은 양의 컴퓨팅 용량에 대한 액세스를 포함하여 몇 가지 요인에 의해 주도되었습니다. Amazon은 25년 동안 기계 학습을 광범위하게 사용해 왔으며 개인화된 전자 상거래 권장 사항부터 주문 처리 센터 선택 경로, Prime Air용 드론, Alexa, AWS가 제공하는 많은 기계 학습 서비스(AWS가 가장 광범위한 기계를 보유한 곳) 모든 클라우드 공급자의 학습 기능 및 고객 기반). 보다 최근에는 GeneraTve AI라고 하는 새로운 형태의 기계 학습이 등장하여 기계 학습 채택을 크게 가속화할 것이라고 약속합니다. 제너레이티브 AI는 매우 큰 언어 모델(최대 천억 개의 매개변수에 대해 훈련되고 계속 증가하고 있음)을 기반으로 하며 광범위한 데이터 세트에 걸쳐 매우 일반적이고 광범위한 리콜 및 학습 기능을 갖추고 있습니다. 우리는 한동안 자체 LLM에 대해 작업해 왔으며 이것이 거의 모든 고객 경험을 변화시키고 개선할 것이라고 믿으며 모든 소비자, 판매자, 브랜드 및 제작자 경험에 걸쳐 이러한 모델에 계속해서 상당한 투자를 할 것입니다. 또한 AWS에서 수년간 해왔듯이 모든 규모의 회사가 제너레이티브 AI를 활용할 수 있도록 이 기술을 민주화하고 있습니다. AWS는 Trainium 및 InferenTa에서 가장 가격 대비 성능이 뛰어난 기계 학습 칩을 제공하므로 소규모 및 대규모 기업이 프로덕션 환경에서 LLM을 교육하고 실행할 수 있습니다. 우리는 회사가 다양한 LLM 중에서 선택하고 고객이 사용하는 데 익숙한 모든 AWS 보안, 개인 정보 보호 및 기타 기능을 갖춘 애플리케이션을 구축할 수 있도록 합니다. 또한 실시간으로 코드 제안을 생성하여 개발자 생산성을 혁신하는 AWS의 CodeWhisperer와 같은 애플리케이션을 제공하고 있습니다. LLM과 GeneraTve AI가 그렇게 변혁적일 것이라고 생각하기 때문에 전체 편지를 쓸 수 있지만 향후 편지로 남겨두겠습니다. LLM과 GeneraTve AI가 고객, 주주 및 Amazon에게 큰 문제가 될 것이라고 가정해 보겠습니다.  그래서 마지막으로 저는 우리가 이 도전적인 거시경제 시대에 진입했을 때보다 더 강력한 위치에서 등장할 것이라고 낙관합니다. 여기에는 몇 가지 이유가 있으며 위에서 많은 이유를 언급했습니다. 그러나 우리의 엄청난 미래 기회를 강조하는 두 가지 비교적 간단한 통계가 있습니다. 우리는 2022년에 4,340억 달러 규모의 소비자 비즈니스를 보유하고 있지만, 전 세계 소매업의 전체 시장 부문 점유율의 대부분은 여전히 물리적 매장에 있습니다(약 80%). 그리고 2022년에 AWS 수익이 800억 달러이고 글로벌 IT 지출의 약 90%가 여전히 온프레미스에 있지만 아직 클라우드로 마이그레이션하지 않는 글로벌 IT 지출에 대한 유사한 이야기입니다. 우리가 이미 보고 있는 것처럼 이러한 방정식이 꾸준히 역전됨에 따라 우리는 선도적인 고객 경험, 끊임없는 발명, 고객 중심 및 노력이 향후 몇 년 동안 상당한 성장을 가져올 것이라고 믿습니다. 그리고 물론 여기에는 Amazon에서 추구하는 다른 비즈니스와 경험이 포함되지 않으며 모두 아직 초기 단계입니다.  저는 우리의 최고의 날이 우리 앞에 와 있다고 굳게 믿으며, 그렇게 되도록 Amazon의 팀원들과 협력하기를 기대합니다.\n",
      "\n",
      "위의 내용을 Korean으로 bullet point 3개로 요약합니다:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m 아마존의 연례 주주 서한 내용을 3개의 한국어 bullet point로 요약하면 다음과 같습니다:\n",
      "\n",
      "- 아마존은 1997년 설립 이후 도서 판매 중심에서 온라인 소매, 클라우드 컴퓨팅 서비스, 디지털 미디어 등으로 사업을 확장했습니다. \n",
      "\n",
      "- 아마존은 경기 침체기나 운영 문제로 어려움을 겪었지만, 고객 경험 향상에 집중하며 장기적인 비즈니스 비전을 유지했습니다.\n",
      "\n",
      "- 아마존은 지속적인 변화와 혁신을 통해 세계 최대 온라인 소매 기업으로 성장했습니다.\n",
      "\n",
      " 아마존의 위 내용을 3개의 bullet point로 요약하면 다음과 같습니다:\n",
      "\n",
      "- 아마존은 AWS에 계속 투자하기로 장기적인 결정을 내렸다. 15년 후 AWS는 연간 850억 달러 규모의 강력한 수익성을 가진 기업으로 성장했다. \n",
      "\n",
      "- 아마존은 각 비즈니스와 이니셔티브를 자세히 검토하고 수익성, 비용 효율성 등을 고려하여 몇몇 사업을 종료 또는 조정했다. \n",
      "\n",
      "- 아마존은 직원들에게 주 5일 중 최소 3일은 사무실 출근을 요청하며, 직원들의 협업과 아이디어 교류를 위해 사무실 출근이 중요하다는 입장을 밝혔다.\n",
      "\n",
      " - 아마존은 주문 처리 네트워크를 전국 단일 네트워크에서 지역화된 네트워크로 전환했습니다. \n",
      "\n",
      "- 이를 위해 미국을 8개의 작은 지리적 영역으로 나누고, 각 영역 내에서 주문 처리 센터와 배송 스테이션을 연결했습니다.\n",
      "\n",
      "- 이 변화로 더 많은 재고를 지역 내에 분산하고, 지역 내에서 주문한 제품만 배송함으로써 배송 속도를 높이고 비용을 절감했습니다.\n",
      "\n",
      " - AWS는 물류 시스템과 인프라를 개선하여 지역별로 자급자족할 수 있도록 하고 배송 거리와 비용을 줄였습니다.\n",
      "\n",
      "- 고급 기계 학습 알고리즘을 사용하여 각 지역의 고객 수요를 더 잘 예측하여 올바른 재고를 보유합니다. \n",
      "\n",
      "- AWS는 고객의 경제적 어려움을 고려하여 비용 최적화를 지원하고 있으며, 장기적인 고객 관계 유지에 주력하고 있습니다.\n",
      "\n",
      " - AWS는 계속해서 새로운 기능과 서비스를 출시하고 있습니다. 예를 들어 Graviton과 Trainium, InferenTa 등의 칩을 개발하여 고객에게 더 나은 가격 대 성능을 제공하고 있습니다.\n",
      "\n",
      "- 기계 학습의 성장으로 인해 AWS의 교육과 추론 칩을 사용하면 훨씬 저렴한 비용으로 더 많은 작업을 수행할 수 있습니다. \n",
      "\n",
      "- 아마존의 광고 비즈니스도 고객의 쇼핑 행동 데이터와 기계 학습 알고리즘을 활용하여 더 유용한 광고를 제공하고, 브랜드에 더 나은 성과를 제공하고 있습니다.\n",
      "\n",
      " - 아마존은 광고주가 자신의 브랜드를 구축할 수 있는 최고의 플랫폼이 되기 위해 기계 학습을 통한 광고 선택 알고리즘 개선에 투자하고 있습니다.\n",
      "\n",
      "- 아마존은 Amazon MarkeTng Cloud(AMC)를 통해 광고주가 개인정보를 보호하면서 데이터 분석과 광고 효과 측정을 할 수 있습니다. \n",
      "\n",
      "- 아마존은 미래의 광고 기회로 비디오, 라이브 스포츠, 오디오, 식료품과 같은 새로운 분야를 지속적으로 모색하고 있습니다.\n",
      "\n",
      " - 아마존은 신흥국가인 인도, 브라질, 멕시코 등에 투자를 했으며, 이들 국가의 성장 패턴이 북미와 유사하다고 평가했습니다. \n",
      "\n",
      "- 아마존은 식료품 사업을 확장하고자 Whole Foods Market을 인수했습니다. 또한 Amazon Fresh를 통해 대량 식료품 사업 모델을 개발하고 있습니다.\n",
      "\n",
      "- 아마존 비즈니스는 기업 고객을 대상으로 사무용품 등 대량 품목의 조달 서비스를 제공하고 있으며, 이 서비스가 번창하고 있다고 했습니다.\n",
      "\n",
      " - 아마존은 Buy with Prime 서비스를 통해 타사 웹사이트에서의 구매 전환률을 25%까지 높였습니다. 이 서비스는 타사 웹사이트에서 아마존 프라임 회원을 대상으로 무료 배송과 간편한 결제를 제공합니다.\n",
      "\n",
      "- 아마존은 2020년 온라인 약국 서비스인 아마존 파마시를 시작했습니다. 이 서비스는 프라임 회원에게 투명한 가격과 리필 편의성을 제공합니다. \n",
      "\n",
      "- 아마존은 RxPass 서비스를 통해 프라임 회원이 매월 정액 요금으로 일반 질환 약물을 구입할 수 있게 합니다. 하지만 고객은 아마존이 더 나은 의료 서비스 대안을 제공하기를 기대하고 있습니다.\n",
      "\n",
      " - Amazon은 One Medical을 인수하여 환자 중심의 디지털 의료 서비스를 제공하고자 합니다. One Medical의 앱과 사무실 네트워크를 통해 환자들이 더 쉽게 의료 서비스를 이용할 수 있습니다.\n",
      "\n",
      "- Kuiper 프로젝트를 통해 Amazon은 저궤도 위성을 사용하여 전 세계적으로 널리 퍼진 지역까지 고품질의 광대역 인터넷을 제공하고자 합니다. 이를 통해 여러 서비스와 교육 기회에 대한 접근성을 높입니다.\n",
      "\n",
      "- Amazon은 AI, 머신 러닝, LLM 등 새로운 기술에 대한 투자를 강화하고 있습니다. 이를 통해 미래 사업 기회를 발굴하고자 합니다.\n",
      "\n",
      " Amazon의 미래 성장 가능성을 요약한 3개의 bullet point는 다음과 같습니다:\n",
      "\n",
      "- 전 세계 소매 시장의 대부분이 아직 물리적 매장에 집중되어 있지만, 온라인 쇼핑은 지속적으로 성장하고 있습니다. \n",
      "\n",
      "- 글로벌 IT 지출의 대부분이 아직 온프레미스에 집중되어 있지만, 클라우드로의 이전은 꾸준히 증가할 것으로 예상합니다.\n",
      "\n",
      "- Amazon은 고객 경험 개선, 지속적인 발명, 고객 중심의 노력을 통해 향후 몇 년간 상당한 성장을 이룰 것으로 보입니다.\n",
      "\n",
      "위의 내용을 Korean으로 간결하게 bullet point 5개로 요약합니다:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " 아마존 주주 서한 요약 내용은 다음과 같습니다:  - 아마존은 도서 판매에서 소매, 클라우드, 미디어 등으로 사업을 확장했습니다.  - 고객 경험 향상에 집중하며 장기 비전을\n",
      "유지했습니다.   - 지속적인 변화와 혁신을 통해 세계 1위 온라인 기업으로 성장했습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "import textwrap\n",
    "                                       \n",
    "map_prompt_template = \"{text}\\n\\n위의 내용을 Korean으로 bullet point 3개로 요약합니다:\"\n",
    "map_prompt = PromptTemplate(template=map_prompt_template, input_variables=[\"text\"])\n",
    "\n",
    "combine_prompt_template = \"{text}\\n\\n위의 내용을 Korean으로 간결하게 bullet point 5개로 요약합니다:\"\n",
    "combine_prompt = PromptTemplate(template=combine_prompt_template, input_variables=[\"text\"])\n",
    "\n",
    "chain = load_summarize_chain(llm, chain_type=\"map_reduce\", map_prompt=map_prompt, combine_prompt=combine_prompt, verbose=True)\n",
    "\n",
    "output_summary = chain.run(docs)\n",
    "\n",
    "wrapped_text = textwrap.fill(output_summary, width=100)\n",
    "print(wrapped_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea8ec90-74cb-476b-a401-6aa4f7e2d0a9",
   "metadata": {},
   "source": [
    "## Streamlit 어플리케이션 수행하기\n",
    "\n",
    "#### (1) 어플리케이션 수행을 위한 스크립트 준비하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc0abc3b-b1ee-46f2-8527-fb50a7353559",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting summarize_lib.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile summarize_lib.py\n",
    "\n",
    "import os\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "def get_llm():\n",
    "    \n",
    "    model_kwargs =  { #Anthropic 모델\n",
    "        \"max_tokens_to_sample\": 8000,\n",
    "        \"temperature\": 0, \n",
    "        \"top_k\": 250, \n",
    "        \"top_p\": 0.5, \n",
    "        \"stop_sequences\": [\"\\n\\nHuman:\"] \n",
    "    }\n",
    "    \n",
    "    llm = Bedrock(\n",
    "        credentials_profile_name=os.environ.get(\"AWS_PROFILE\"), #AWS 자격 증명에 사용할 프로필 이름을 설정합니다(기본값이 아닌 경우)\n",
    "        region_name=os.environ.get(\"AWS_DEFAULT_REGION\"), #리전 이름을 설정합니다(기본값이 아닌 경우)\n",
    "        endpoint_url=os.environ.get(\"BEDROCK_ENDPOINT_URL\"), #엔드포인트 URL 설정(필요한 경우)\n",
    "        #model_id=\"anthropic.claude-v2\", #파운데이션 모델 설정하기\n",
    "        model_id=\"anthropic.claude-instant-v1\", #파운데이션 모델 설정하기\n",
    "        model_kwargs=model_kwargs) #Claude의 속성을 구성합니다.\n",
    "    \n",
    "    return llm\n",
    "\n",
    "pdf_path = \"uploaded_file.pdf\"\n",
    "\n",
    "def get_example_file_bytes(): #사용자가 기존 생성된 예제를 다운로드할 수 있도록 파일 바이트를 제공합니다.\n",
    "    with open(\"2022-Shareholder-Letter-ko.pdf\", \"rb\") as file:\n",
    "        file_bytes = file.read()\n",
    "    \n",
    "    return file_bytes\n",
    "\n",
    "\n",
    "def save_file(file_bytes): #업로드한 파일을 디스크에 저장하여 나중에 요약합니다.   \n",
    "    with open(pdf_path, \"wb\") as f: \n",
    "        f.write(file_bytes)\n",
    "    \n",
    "    return f\"Saved {pdf_path}\"\n",
    "\n",
    "\n",
    "def get_docs():\n",
    "    \n",
    "    loader = PyPDFLoader(file_path=pdf_path)\n",
    "    documents = loader.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        separators=[\"\\n\\n\", \"\\n\"], chunk_size=4000, chunk_overlap=100 \n",
    "    )\n",
    "    docs = text_splitter.split_documents(documents=documents)\n",
    "    \n",
    "    return docs\n",
    "\n",
    "def get_summary(return_intermediate_steps=False):\n",
    "    \n",
    "    map_prompt_template = \"{text}\\n\\n위의 내용을 Korean으로 bullet point 3개로 요약합니다:\"\n",
    "    map_prompt = PromptTemplate(template=map_prompt_template, input_variables=[\"text\"])\n",
    "    \n",
    "    combine_prompt_template = \"{text}\\n\\n위의 내용을 Korean으로 간결하게 bullet point 5개로 요약합니다:\"\n",
    "    combine_prompt = PromptTemplate(template=combine_prompt_template, input_variables=[\"text\"])\n",
    "    \n",
    "    llm = get_llm()\n",
    "    docs = get_docs()\n",
    "    \n",
    "    chain = load_summarize_chain(\n",
    "        llm, chain_type=\"map_reduce\", \n",
    "        map_prompt=map_prompt, \n",
    "        combine_prompt=combine_prompt, \n",
    "        return_intermediate_steps=return_intermediate_steps,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    if return_intermediate_steps:\n",
    "        return chain({\"input_documents\": docs}, return_only_outputs=True) #반환 구조를 chain.run(docs)와 일관성 있게 만들기\n",
    "    else:\n",
    "        return chain.run(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98f755a0-0214-4d02-a6ba-8bdcdec834d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting summarize_app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile summarize_app.py\n",
    "\n",
    "import streamlit as st\n",
    "import summarize_lib as glib\n",
    "\n",
    "st.set_page_config(layout=\"wide\", page_title=\"문서 요약\")\n",
    "st.title(\"문서 요약\")\n",
    "\n",
    "uploaded_file = st.file_uploader(\"Select a PDF\", type=['pdf'])\n",
    "\n",
    "upload_button = st.button(\"Upload\", type=\"primary\")\n",
    "\n",
    "if upload_button:\n",
    "    with st.spinner(\"Uploading...\"):\n",
    "        \n",
    "        upload_response = glib.save_file(file_bytes=uploaded_file.getvalue())\n",
    "\n",
    "        st.success(upload_response)\n",
    "        \n",
    "        st.session_state.has_document = True\n",
    "\n",
    "if 'has_document' in st.session_state: #문서가 업로드되었는지 확인하기\n",
    "    \n",
    "    return_intermediate_steps = st.checkbox(\"중간 단계 요약 보기\", value=True)\n",
    "    summarize_button = st.button(\"요약하기\", type=\"primary\")\n",
    "    \n",
    "    if summarize_button:\n",
    "        st.subheader(\"통합 요약\")\n",
    "\n",
    "        with st.spinner(\"Running...\"):\n",
    "            response_content = glib.get_summary(return_intermediate_steps=return_intermediate_steps)\n",
    "\n",
    "\n",
    "        if return_intermediate_steps:\n",
    "\n",
    "            st.write(response_content[\"output_text\"])\n",
    "\n",
    "            st.subheader(\"중간 단계 요약\")\n",
    "\n",
    "            for step in response_content[\"intermediate_steps\"]:\n",
    "                st.write(step)\n",
    "                st.markdown(\"---\")\n",
    "\n",
    "        else:\n",
    "            st.write(response_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4c58ab4-9e7e-4a14-906b-80ded1458cc4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting summ-setup.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile summ-setup.sh\n",
    "\n",
    "pip install --no-cache-dir -r ./dependencies/requirements.txt\n",
    "pip install anthropic\n",
    "sudo yum install -y jq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7c7c78e-62c6-48d9-87af-9381a726dab0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting summ-run.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile summ-run.sh\n",
    "\n",
    "#!/bin/sh\n",
    "CURRENTDATE=`date +\"%Y-%m-%d %T\"`\n",
    "RED='\\033[0;31m'\n",
    "CYAN='\\033[1;36m'\n",
    "GREEN='\\033[1;32m'\n",
    "NC='\\033[0m'\n",
    "S3_PATH=$1\n",
    "\n",
    "# Run the Streamlit app and save the output to \"temp.txt\"\n",
    "streamlit run summarize_app.py > temp.txt & \n",
    "\n",
    "# Read the text file using cat\n",
    "echo \"Getting the URL to view your Streamlit app in the browser\"\n",
    "\n",
    "# Extract the last four digits of the port number from the Network URL\n",
    "sleep 5\n",
    "PORT=$(grep \"Network URL\" temp.txt | awk -F':' '{print $NF}' | awk '{print $1}' | tail -c 5)\n",
    "echo -e \"${CYAN}${CURRENTDATE}: [INFO]:${NC} Port Number ${PORT}\" \n",
    "\n",
    "\n",
    "# Get Studio domain information\n",
    "DOMAIN_ID=$(jq .DomainId /opt/ml/metadata/resource-metadata.json || exit 1)\n",
    "RESOURCE_NAME=$(jq .ResourceName /opt/ml/metadata/resource-metadata.json || exit 1)\n",
    "RESOURCE_ARN=$(jq .ResourceArn /opt/ml/metadata/resource-metadata.json || exit 1)\n",
    "\n",
    "# Remove quotes from string\n",
    "DOMAIN_ID=`sed -e 's/^\"//' -e 's/\"$//' <<< \"$DOMAIN_ID\"`\n",
    "RESOURCE_NAME=`sed -e 's/^\"//' -e 's/\"$//' <<< \"$RESOURCE_NAME\"`\n",
    "RESOURCE_ARN=`sed -e 's/^\"//' -e 's/\"$//' <<< \"$RESOURCE_ARN\"`\n",
    "RESOURCE_ARN_ARRAY=($(echo \"$RESOURCE_ARN\" | tr ':' '\\n'))\n",
    "\n",
    "# Get Studio domain region\n",
    "REGION=$(echo \"${RESOURCE_ARN_ARRAY[3]}\")\n",
    "\n",
    "# Check if it's Collaborative Space\n",
    "SPACE_NAME=$(jq .SpaceName /opt/ml/metadata/resource-metadata.json || exit 1)\n",
    "\n",
    "# if it's not a collaborative space \n",
    "if [ -z \"$SPACE_NAME\" ] || [ $SPACE_NAME == \"null\" ] ;\n",
    "then\n",
    "    # If it's a user-profile access\n",
    "    echo -e \"${CYAN}${CURRENTDATE}: [INFO]:${NC} Domain Id ${DOMAIN_ID}\"\n",
    "    STUDIO_URL=\"https://${DOMAIN_ID}.studio.${REGION}.sagemaker.aws\"\n",
    "    \n",
    "# It is a collaborative space\n",
    "else\n",
    "\n",
    "    SEM=true\n",
    "    SPACE_ID=\n",
    "\n",
    "    # Check if Space Id was previously configured\n",
    "    if [ -f /tmp/space-metadata.json ]; then\n",
    "        SAVED_SPACE_ID=$(jq .SpaceId /tmp/space-metadata.json || exit 1)\n",
    "        SAVED_SPACE_ID=`sed -e 's/^\"//' -e 's/\"$//' <<< \"$SAVED_SPACE_ID\"`\n",
    "\n",
    "        if [ -z \"$SAVED_SPACE_ID\" ] || [ $SAVED_SPACE_ID == \"null\" ]; then\n",
    "            ASK_INPUT=true\n",
    "        else\n",
    "            ASK_INPUT=false\n",
    "        fi\n",
    "    else\n",
    "        ASK_INPUT=true\n",
    "    fi\n",
    "\n",
    "    # If Space Id is not available, ask for it\n",
    "    while [[ $SPACE_ID = \"\" ]] ; do\n",
    "        # If Space Id already configured, skeep the ask\n",
    "        if [ \"$ASK_INPUT\" = true ]; then\n",
    "            echo -e \"${CYAN}${CURRENTDATE}: [INFO]:${NC} Please insert the Space Id from your url. e.g. https://${GREEN}<SPACE_ID>${NC}.studio.${REGION}.sagemaker.aws/jupyter/default/lab\"\n",
    "            read SPACE_ID\n",
    "            SEM=true\n",
    "        else\n",
    "            SPACE_ID=$SAVED_SPACE_ID\n",
    "        fi\n",
    "\n",
    "        if ! [ -z \"$SPACE_ID\" ] && ! [ $SPACE_ID == \"null\" ] ;\n",
    "        then\n",
    "            while $SEM; do\n",
    "                echo \"${SPACE_ID}\"\n",
    "                read -p \"Should this be used as Space Id? (y/N) \" yn\n",
    "                case $yn in\n",
    "                    [Yy]* )\n",
    "                        echo -e \"${CYAN}${CURRENTDATE}: [INFO]:${NC} Domain Id ${DOMAIN_ID}\"\n",
    "                        echo -e \"${CYAN}${CURRENTDATE}: [INFO]:${NC} Space Id ${SPACE_ID}\"\n",
    "\n",
    "                        jq -n --arg space_id $SPACE_ID '{\"SpaceId\":$space_id}' > /tmp/space-metadata.json\n",
    "\n",
    "                        STUDIO_URL=\"https://${SPACE_ID}.studio.${REGION}.sagemaker.aws\"\n",
    "\n",
    "                        SEM=false\n",
    "                        ;;\n",
    "                    [Nn]* ) \n",
    "                        SPACE_ID=\n",
    "                        ASK_INPUT=true\n",
    "                        SEM=false\n",
    "                        ;;\n",
    "                    * ) echo \"Please answer yes or no.\";;\n",
    "                esac\n",
    "            done\n",
    "        fi\n",
    "    done\n",
    "fi\n",
    "\n",
    "echo -e \"${CYAN}${CURRENTDATE}: [INFO]:${NC} Studio Url ${STUDIO_URL}\"\n",
    "\n",
    "\n",
    "link=\"${STUDIO_URL}/jupyter/${RESOURCE_NAME}/proxy/${PORT}/\"\n",
    "\n",
    "echo -e \"${CYAN}${CURRENTDATE}: [INFO]:${NC} Starting Streamlit App\"\n",
    "echo -e \"${CYAN}${CURRENTDATE}: [INFO]: ${GREEN}${link}${NC}\"\n",
    "\n",
    "exit 0\n",
    "fi\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c256f652-b4d1-4ecd-9bc7-7a471377a2c0",
   "metadata": {},
   "source": [
    "## (2) Streamlit 어플리케이션 실행하기\n",
    "\n",
    "1. listing 어플리케이션 수행을 위한 디렉토리 경로로 이동합니다.\n",
    "    \n",
    "    cd /aws-gen-for-retail/l_lab\n",
    "    \n",
    "2. Streamlit 수행을 위한 라이브러리를 설치합니다. \n",
    "\n",
    "    . summ-setup.sh\n",
    "\n",
    "3. Streamlit 실행을 위한 스크립트를 수행합니다. \n",
    "\n",
    "    . summ-run.sh \n",
    "\n",
    "4. 스크립트 수행 결과 생성되는 링크를 클릭하면 Streamlit 어플리케이션을 시작할 수 있습니다. \n",
    "\n",
    "5. '2022-Shareholder-Letter-ko.pdf'를 1_lab 폴더에서 다운로드한 후, 실행 중인 어플리케이션에서 해당 파일을 업로드 합니다.\n",
    "\n",
    "![bedrock_langchian_image](./image/summ-web1.png)\n",
    "\n",
    "\n",
    "6. '중간단계' 요약하기를 클릭한 후, '요약하기' 버튼을 클릭합니다. \n",
    "\n",
    "![bedrock_langchian_image](./image/summ-web2.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b71dec3-fddd-4ebb-8af2-f6e4d5e044ed",
   "metadata": {},
   "source": [
    "# 추가 실습\n",
    "\n",
    "## STUFF \n",
    "'Stuff(스터핑)' 체인은 스터핑이라는 더 간단한 접근 방식을 활용합니다. 이 접근 방식에서는 프롬프트가 모든 관련 데이터를 컨텍스트로서 언어 모델에 전달합니다. 이 접근 방식은 작은 데이터 조각에는 효과적이지만 많은 데이터를 처리할 때는 비실용적입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85fe93f9-d1ef-43f2-9c97-0666a86c7e5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mCEO로서 두 번째 연례 주주 서한을 작성하기 위해 자리에 앉았을 때 저는 Amazon의 앞날에 대해 낙관적이고 활력을 얻었습니다. 2022년은 최근 기억에 있어 어려운 거시경제적 해 중 하나이고 우리 자체의 운영상의 어려움에도 불구하고 우리는 여전히 수요를 늘릴 방법을 찾았습니다(팬데믹 전반기에 경험한 전례 없는 성장에 더해). 우리는 장단기적으로 고객 경험을 의미 있게 개선하기 위해 대규모 사업을 혁신했습니다. 그리고 고객, 주주 및 직원을 위해 Amazon의 미래를 바꿀 수 있다고 믿는 장기 투자를 계속 유지하면서 투자 결정과 앞으로 나아갈 방법에 중요한 조정을 했습니다.  작년에 이례적인 수의 동시 도전 과제가 있었지만 현실은 유능하고 자금이 충분한 경쟁자가 많은 크고 역동적인 글로벌 시장 부문에서 운영하는 경우(아마존이 모든 비즈니스를 운영하는 조건) 조건이 오랫동안 정체되어 있는 경우는 드뭅니다.  제가 Amazon에 근무한 25년 동안 끊임없는 변화가 있었고 그 중 대부분은 우리가 스스로 시작했습니다. 내가 1997년에 Amazon에 입사했을 때 우리는 1996년에 1,500만 달러의 매출을 올렸고, 도서 전용 소매업체였으며, 제3자 시장이 없었고, 미국 내 주소로만 배송되었습니다. 오늘날 Amazon은 단위 판매의 60%를 차지하고 전 세계 거의 모든 국가의 고객에게 도달하는 활기찬 타사 판매자 에코시스템을 통해 상상할 수 있는 거의 모든 물리적 및 디지털 소매 품목을 판매합니다. 마찬가지로 클라우드에서 일련의 기술 인프라 서비스를 중심으로 비즈니스를 구축하는 것은 AWS를 추구하기 시작한 2003년에는 분명하지 않았으며 2006년 첫 서비스를 출시했을 때도 마찬가지였습니다. 거의 모든 책을 60초 안에 손끝에서 볼 수 있습니다 2007년 Kindle을 출시했을 때 가벼운 디지털 리더에 저장하고 검색할 수 있다는 것은 아직 \"사물\"이 아니었고 Alexa(2014년 출시)와 같이 액세스하는 데 사용할 수 있는 음성 기반 개인 비서도 아니었습니다. 엔터테인먼트, 스마트 홈 제어, 쇼핑 및 모든 종류의 정보 검색.  또한 거시 경제 상황이나 운영 비효율성으로 인해 우리에게 새로운 과제가 제시된 경우도 있었습니다. 예를 들어 2001년 닷컴 폭락 당시 우리는 연휴 기간 동안 재고를 구매하기 위해 신용장을 확보해야 했고 비즈니스의 더 나은 수익성을 제공하기 위해 비용을 합리화해야 했지만 여전히 우리가 노력하고 있던 장기적인 고객 경험과 비즈니스를 우선시했습니다. 빌드(기억한다면, 우리는 실제로 2001년 그 미미한 기간 동안 대부분의 범주에서 가격을 낮췄습니다). 2008-2009년에 모기지 담보 증권 금융 위기로 촉발된 경기 침체를 견디면서 이런 종류의 균형을 다시 보았습니다. 우리는 매장 비즈니스의 비용 구조와 효율성을 관리하기 위해 몇 가지 조치를 취했지만, 주주에게 강력한 수익을 제공하는 실질적인 미래 비즈니스가 될 수 있다고 생각하는 고객 경험에 대한 투자와 이러한 합리화의 균형을 맞췄습니다. 2008년에 AWS는 여전히 상당히 작고 신생 기업이었습니다. 우리는 우리가 무언가를 하고 있다는 것을 알고 있었지만\n",
      "\n",
      "여전히 상당한 자본 투자가 필요했습니다. 회사 안팎에서는 아마존(당시 주로 온라인 소매업체로 알려짐)이 클라우드 컴퓨팅에 많은 투자를 하는 이유에 대해 의문을 제기하는 목소리가 있었습니다. 그러나 우리는 미래에 고객과 아마존을 위해 많은 가치를 창출할 수 있는 특별한 것을 발명하고 있다는 것을 알고 있었습니다. 우리는 잠재적 경쟁자보다 먼저 출발했습니다. 무엇보다 우리는 혁신 속도를 가속화하고 싶었습니다. 우리는 AWS에 계속 투자하기로 장기적인 결정을 내렸습니다. 15년 후 AWS는 이제 신생 기업에서 다국적 기업, 공공 부문 조직에 이르기까지 고객이 기술 인프라를 관리하는 방식을 변화시킨 강력한 수익성을 갖춘 연간 매출 850억 달러 규모의 기업이 되었습니다. 2008-2009년 기간 동안 AWS에 대한 투자를 늦추었다면 Amazon은 다른 회사가 되었을 것입니다.  변화는 항상 가까이에 있습니다. 때로는 적극적으로 초대하고 때로는 그냥 노크합니다. 그러나 그것이 오는 것을 보았을 때, 그것을 받아들여야 합니다. 그리고 장기간에 걸쳐 이를 잘 수행하는 회사는 일반적으로 성공합니다. 나는 우리 팀이 우리 앞에 보이는 변화에 대응하는 방식이 마음에 들기 때문에 우리의 미래 전망에 대해 낙관적입니다.  지난 몇 달 동안 우리는 회사 전체를 비즈니스별로, 발명별로 자세히 살펴보고 각 이니셔티브의 장기적인 잠재력에 대해 충분한 수익, 운영 수입, 무료 현금 흐름, 투자 자본 수익률. 경우에 따라 특정 비즈니스를 폐쇄하게 되었습니다. 예를 들어 우리는 서점 및 4스타 매장과 같은 물리적 매장 개념 추구를 중단하고 Amazon Fabric 및 Amazon Care 노력을 중단했으며 의미 있는 수익을 얻을 수 있는 경로가 보이지 않는 일부 최신 장치에서 전환했습니다. 다른 경우에는 우리가 기대했던 수익을 내지 못하는 일부 프로그램(예: $35 이상의 모든 온라인 식료품 주문에 대한 무료 배송)을 살펴보고 수정했습니다. 우리는 또한 리소스를 어디에 사용할지 우선 순위를 재지정했고, 결국 27,000개의 회사 역할을 제거하는 어려운 결정을 내렸습니다. 전체 비용을 합리화하기 위해 지난 몇 개월 동안 수행한 다른 변경 사항이 많이 있으며 대부분의 리더십 팀과 마찬가지로 비즈니스에서 보고 있는 사항을 계속 평가하고 적응적으로 진행할 것입니다.  우리는 또한 팀으로 어떻게 협력하고 있는지 열심히 살펴보았고 회사 직원들에게 5월부터 일주일에 최소 3일은 사무실로 돌아올 것을 요청했습니다. 팬데믹 기간 동안 우리 직원들은 집에서 일하기 위해 집결했으며 예상치 못한 상황에 대처하기 위해 가능한 모든 일을 했습니다. 그것은 인상적이었고 저는 우리의 집단적 팀이 고객, 지역 사회 및 비즈니스에 대한 전례 없는 도전을 극복하기 위해 함께 모인 방식이 자랑스럽습니다. 그러나 우리는 이것이 최선의 장기적 접근 방식이라고 생각하지 않습니다. 우리는 함께 일하고 직접 서로에게서 배울 때 협업과 발명이 더 쉽고 효과적이라는 것을 확신하게 되었습니다. 서로의 아이디어에 대한 에너지와 반복은 더 자유롭게 발생하며 최고의 Amazon 발명품 중 다수는 사람들이 회의 후 뒤에 남아 화이트보드에서\n",
      "\n",
      "아이디어를 검토하거나 회의에서 돌아오는 길에 대화를 계속하면서 획기적인 순간을 맞이했습니다. , 또는 다른 생각으로 그날 늦게 팀원의 사무실에 들르는 것. 발명은 종종 지저분합니다. 그것은 방황하고 구불 구불하고 마리 네이드합니다. 뜻밖의 상호 작용이 도움이 되며, 가상으로 하는 것보다 직접 만나는 것이 더 많습니다. 또한 우리가 대부분의 시간을 함께 사무실에 있고 동료들에게 둘러싸여 있을 때 우리 문화를 배우고, 모델링하고, 연습하고, 강화하는 것이 훨씬 더 쉽습니다. 혁신과 우리 고유의 문화는 회사로서 처음 29년 동안 매우 중요했으며 다음 29년에도 마찬가지로 그렇게 될 것으로 기대합니다.  우리가 계속해서 해결해야 할 중요한 문제는 매장 주문 처리 네트워크에서 서비스를 제공하는 데 드는 비용(예: Amazon에서 고객에게 제품을 제공하는 비용)이 증가하는 것입니다. 비용 및 배송 속도.  팬데믹 초기에는 많은 오프라인 매장이 문을 닫았고, 우리 소비자 비즈니스는 놀라운 속도로 성장하여 연간 매출이 2019년 2,450억 달러에서 2022년 4,340억 달러로 증가했습니다. 이는 주문 처리 센터 공간을 두 배로 늘려야 함을 의미했습니다. 지난 25년 동안 우리가 구축한 운송 네트워크를 현재 UPS 크기의 라스트 마일 운송 네트워크 구축을 크게 가속화했습니다(항목이 장거리를 통과해야 할 때 효율성과 속도를 지원하기 위한 새로운 분류 센터 네트워크 포함). 약 2년의 시간 동안. 이것은 쉬운 일이 아니었고 수십만 명의 아마존 사람들이 이것을 실현하기 위해 매우 열심히 일했습니다. 그러나 이러한 변화의 속도와 규모로 인해 의도한 생산성을 얻기 위해서는 많은 최적화가 필요했습니다. 지난 몇 달 동안 우리는 주문 처리 센터 및 운송 네트워크의 모든 프로세스 경로를 면밀히 조사하고 수십 가지 프로세스 및 메커니즘을 재설계하여 지난 몇 분기 동안 꾸준한 생산성 향상과 비용 절감을 가져왔습니다. 해야 할 일이 더 많지만 우리의 궤적과 우리 앞에 있는 의미 있는 상승세에 만족합니다.  우리는 또한 앞으로 수년 동안 더 낮은 비용과 더 빠른 속도를 제공할 수 있도록 더 큰 구조적 변화를 만들기 위해 이 기회를 잡았습니다. 좋은 예는 미국 주문 처리 네트워크가 어떻게 구성되어 있는지 재평가하는 것입니다. 최근까지 아마존은 미국 전역에 퍼져 있는 주문 처리 센터의 재고를 분배하는 하나의 미국 전국 주문 처리 네트워크를 운영했습니다. 지역 주문 처리 센터에 고객이 주문한 제품이 없으면 결국 다른 지역에서 배송하게 되므로 더 많은 비용이 들고 배송 시간이 늘어납니다. 이 문제는 주문 처리 네트워크가 지난 몇 년 동안 수백 개의 추가 노드로 확장되어 더 많은 위치에 재고를 분배하고 주문 처리 센터와 배송 스테이션 노드를 효율적으로 연결하는 복잡성이 증가함에 따라 더욱 두드러졌습니다. 작년에 우리는 재고 배치 전략을 재설계하고 더 큰 주문 처리 센터 공간을 활용하여 전국 주문 처리 네트워크에서 지역화된 네트워크 모델로 이동하기 시작했습니다. 우리는 더 작은 지리적 영역에 8개의 상호 연결된 지역을 만들기 위해\n",
      "\n",
      "상당한 내부 변경(예: 배치 및 물류 소프트웨어, 프로세스, 물리적 운영)을 수행했습니다. 이러한 각 지역은 대부분 자급자족 방식으로 운영할 수 있는 광범위하고 적절한 선택권을 가지고 있으며 필요할 때 여전히 전국적으로 배송할 수 있습니다. 가장 의미 있고 힘든 작업 중 일부는 이 많은 양의 인프라 간의 연결을 최적화하는 데 있었습니다. 또한 적시에 올바른 지역에 올바른 재고를 보유할 수 있도록 국가의 여러 지역에 있는 고객이 필요로 하는 것이 무엇인지 더 잘 예측하기 위해 고급 기계 학습 알고리즘을 지속적으로 개선하고 있습니다. 최근에 이 지역 출시를 완료했으며 초기 결과가 마음에 듭니다. 이동 거리가 짧다는 것은 서비스 비용이 낮아지고 환경에 미치는 영향이 줄어들며 고객이 주문을 더 빨리 받는 것을 의미합니다. 후자의 경우 더 많은 익일 배송 및 당일 배송을 보게 되어 기쁩니다. 2023년에는 프라임 배송 속도가 가장 빨라질 것입니다. 전반적으로 우리는 비용 절감, 배송 감소 계획에 대해 확신을 가지고 있습니다. 건전한 운영 마진으로 의미 있게 더 큰 소매 사업을 구축하십시오.  AWS는 연간 850억 달러의 수익을 내고 있으며 아직 채택 곡선 초기 단계에 있지만 장기적으로 고객에게 가장 중요한 것에 집중하는 것이 중요한 시점에 있습니다. 2022년에 620억 달러의 수익 기반으로 전년 대비 29%(\"YoY\") 성장했음에도 불구하고 AWS는 기업들이 현재의 어려운 거시 경제 상황을 고려할 때 지출에 더욱 신중을 기하고 있기 때문에 단기적인 역풍에 직면해 있습니다. 일부 회사는 이 어려운 시기에 고객으로부터 최대한 많은 돈을 뽑아낼 수 있는 방법에 집착할 수 있지만 장기적으로 고객이 원하는 것도 고객을 위한 최선도 아니므로 우리는 다른 방식을 취하고 있습니다. AWS와 클라우드 컴퓨팅의 많은 이점 중 하나는 비즈니스가 성장하면 원활하게 확장할 수 있다는 것입니다. 반대로 비즈니스 계약이 체결되면 해당 용량을 반환하고 비용 지불을 중단하도록 선택할 수 있습니다. 이러한 탄력성은 클라우드에 고유하며 자체 온프레미스 데이터 센터, 서버 및 네트워킹 장비에 이미 값비싼 자본 투자를 한 경우에는 존재하지 않습니다. AWS에서는 모든 비즈니스와 마찬가지로 한 분기 또는 1년 동안 최적화하려고 하지 않습니다. 우리는 우리 모두보다 오래 지속되는 고객 관계(및 비즈니스)를 구축하기 위해 노력하고 있습니다. 그 결과 AWS 영업 및 지원 팀은 고객이 이 불확실한 경제를 더 잘 헤쳐나갈 수 있도록 AWS 지출을 최적화하는 데 많은 시간을 할애하고 있습니다. 이러한 AWS 고객 중 다수는 비용 최적화만큼 비용 절감이 아니라 리소스를 가져와 계획 중인 새롭고 독창적인 새로운 고객 경험에 적용할 수 있다고 말합니다. 고객은 이러한 고객 중심의 장기적인 접근 방식을 높이 평가했으며 고객과 AWS 모두에게 좋은 징조가 될 것이라고 생각합니다.  이러한 단기 역풍이 우리의 성장률을 약화시키는 동안 우리는 AWS에서 볼 수 있는 많은 기본 사항을 좋아합니다. 우리의 새로운 고객 파이프라인은 활성 마이그레이션과 마찬가지로 강력합니다. 많은 기업이 이와 같은 비연속 기간을 사용하여 뒤로 물러나 전략적으로 변경하려는 사항을 결정합니다. 자체 인프라 관리를 거부하고 민첩성, 혁신, 비용 절감 효과를 누리기 위해\n",
      "\n",
      "AWS로 이전하는 것을 선호하는 기업이 점점 더 많아지고 있습니다. 효율성 및 보안 이점. 그리고 고객에게 가장 중요한 것은 AWS가 계속해서 새로운 기능을 신속하게 제공하고(2022년에 출시된 3,300개 이상의 새로운 기능 및 서비스) 가능한 것을 변화시키는 장기적인 발명에 투자한다는 것입니다.  칩 개발이 좋은 예입니다. 작년 편지에서 저는 Graviton이라는 범용 CPU 프로세서에 대한 투자에 대해 언급했습니다. Graviton2 기반 컴퓨팅 인스턴스는 비슷한 최신 세대 x86 기반 인스턴스보다 최대 40% 더 나은 가격 대비 성능을 제공합니다. 2022년에는 Graviton2 프로세서보다 25% 향상된 성능을 제공하는 Graviton3 칩을 제공했습니다. 또한 기계 학습 채택이 지속적으로 가속화됨에 따라 고객은 저렴한 GPU(기계 학습에 가장 일반적으로 사용되는 칩)를 원했습니다. AWS는 몇 년 전부터 기계 학습 훈련 및 추론을 위한 이러한 특수 칩에 투자하기 시작했습니다(추론은 기계 학습 모델이 제공하는 예측 또는 답변입니다). 우리는 2022년에 첫 번째 교육용 칩(\"Trainium\")을 제공했습니다. 가장 일반적인 기계 학습 모델의 경우 Trainium 기반 인스턴스는 GPU 기반 인스턴스보다 최대 70% 더 저렴한 비용으로 최대 140% 더 빠릅니다. 대부분의 회사는 아직 교육 단계에 있지만 대규모 생산으로 전환되는 모델을 개발함에 따라 모델은 주기적으로 교육되는 반면 추론은 관련 응용 프로그램으로 항상 발생하기 때문에 대부분의 비용이 추론에 있음을 알게 될 것입니다. 행사중입니다. 우리는 2019년에 첫 번째 추론 칩(\"InferenTa\")을 출시했으며 Amazon과 같은 회사는 이미 1억 달러 이상의 자본 비용을 절감했습니다. 방금 출시된 InferenTa2 칩은 첫 번째 InferenTa 프로세서보다 최대 4배 더 높은 처리량과 10배 더 짧은 대기 시간을 제공합니다. 기계 학습의 엄청난 성장으로 인해 고객은 훨씬 저렴한 비용으로 AWS의 교육 및 추론 칩을 사용하여 훨씬 더 많은 작업을 수행할 수 있습니다. 여기서 혁신이 거의 완료되지 않았으며 이 장기 투자는 고객과 AWS 모두에게 유익한 것으로 입증되어야 합니다. AWS는 아직 진화의 초기 단계에 있으며 향후 10년 동안 비정상적으로 성장할 가능성이 있습니다.  마찬가지로 높은 잠재력을 지닌 Amazon의 광고 비즈니스는 브랜드에 고유한 효과를 발휘하며, 이는 계속해서 빠른 속도로 성장하는 이유 중 하나입니다. 선반 공간, 엔드 캡, 원형 배치를 판매하는 물리적 소매업체의 광고 사업과 유사하게, 당사가 후원하는 제품 및 브랜드 제품은 10년 이상 아마존 쇼핑 경험의 필수적인 부분이었습니다. 그러나 실제 소매업체와 달리 Amazon은 쇼핑 행동에 대해 알고 있는 것과 기계 학습 알고리즘에 대한 우리의 매우 깊은 투자를 고려할 때 이러한 후원 제품을 고객이 검색하는 것과 관련이 있도록 조정할 수 있습니다. 이는 고객에게 더 유용한 광고로 이어집니다. 결과적으로 브랜드에 더 나은 성능을 제공합니다. 이것이 우리의 광고 수익이 지난 2022년 4분기에 23% YoY , 310억 달러 수익 기반에서 2022년에 전체적으로 25% YoY 성장을 지속한 이유 중 하나입니다. 몇 분기.\n",
      "\n",
      "우리는 광고주가 자신의 브랜드를 구축할 수 있는 최고의 장소가 되기 위해 노력합니다. 우리는 그 임무를 달성하는 데 도움이 될 장단기 기회를 가지고 있습니다. 우리는 광고 선택 알고리즘을 계속 연마하기 위해 기계 학습에 많은 투자를 계속하고 있습니다. 지난 몇 년 동안 우리는 포괄적이고 유연하며 내구성 있는 계획 및 측정 솔루션을 구축하는 데 투자하여 마케터에게 광고 효과에 대한 더 큰 통찰력을 제공했습니다. 예를 들어 Amazon MarkeTng Cloud(\"AMC\")가 있습니다. AMC는 광고주가 개인정보를 보호하는 방식으로 자사 및 제3자 입력 범위에서 맞춤 잠재고객 및 캠페인 분석을 실행하여 광고 및 비즈니스 통찰력을 생성하여 광범위한 마케팅 및 판매 전략. 광고 팀과 AWS 팀은 기업이 데이터를 AWS에 저장하고, Amazon 및 기타 타사 데이터 소스와 함께 AMC에서 안전하게 운영하고, AWS에서 분석을 수행하고, Amazon 또는 타사 게시자에서 광고를 활성화할 수 있는 옵션을 갖도록 협력했습니다. Amazon 수요 측 플랫폼을 통해. 고객은 이러한 공동 기능을 정말 좋아합니다. 우리는 또한 광고를 비디오, 라이브 스포츠, 오디오 및 식료품 제품에 신중하게 통합할 미래의 기회를 봅니다. 우리는 브랜드가 적절한 고객과 독특하게 소통하고 비즈니스의 이 부분을 성장시킬 수 있도록 계속 열심히 노력할 것입니다.  격동의 시기에 기존 대기업에만 집중하고 다양한 차원에서 고객을 지원하는 지속 가능하고 오래 지속되며 성장하는 회사를 구축하려는 유혹이 있지만 장기적인 고객 경험을 개발하고 작업하는 것을 멈출 수는 없습니다. 고객과 회사에 의미 있는 영향을 미칠 수 있습니다.  새로운 투자 기회를 모색할 때 다음과 같은 몇 가지 질문을 스스로에게 던집니다.  우리가 성공한다면 규모가 크고 투자 자본에 대한 합리적인 수익을 낼 수 있을까요? 오늘 기회가 잘 제공되고 있습니까? 차별화된 접근 방식이 있습니까? 그리고, 우리는 그 분야에 대한 역량을 가지고 있습니까? 그렇지 않다면 빨리 획득할 수 있습니까? 이러한 질문에 대한 답변이 마음에 들면 투자할 것입니다. 이 과정은 간단해 보이는 일부 확장과 일부 사람들이 처음에 추측하지 못한 확장으로 이어졌습니다.  가장 초기의 예는 단순히 책을 판매하는 것에서 음악, 비디오, 전자 제품 및 장난감과 같은 범주를 추가하는 것으로 확장하기로 선택한 경우입니다. 그 당시(1998-1999)에는 보편적인 박수갈채를 받지 못했지만 돌이켜보면 꽤 분명한 것 같습니다.  해외 매장 확장에 대해서도 마찬가지입니다. 2022년에 우리의 국제 소비자 부문은 1,180억 달러의 수익을 창출했습니다. 더 크고 확립된 국제 소비자 비즈니스에서 우리는 거시경제 상황 둔화의 영향을 받을 만큼 충분히 큽니다. 그러나 2019-2021년에는 영국의 30%, 독일의 26%, 일본의 21%(FX 영향 제외)의 복합 연간 성장률(“CAGR”)로 큰 규모에서 놀라운 성장을 보였습니다. 지난 몇\n",
      "\n",
      "년 동안 우리는 인도, 브라질, 멕시코, 호주, 다양한 유럽 국가, 중동 및 아프리카 일부를 포함한 새로운 국제 지역에 투자했습니다. 이 새로운 국가들은 시작하고 확장하기 위해 일정량의 고정 투자를 받지만 우리는 그들의 궤도가 마음에 들고 그들의 성장 패턴은 우리가 북미와 우리가 확립한 국제 지역에서 본 것과 유사합니다. 신흥 국가에는 때때로 우리 사업이 의존하는 일부 인프라와 서비스(예: 결제 방법, 운송 서비스 및 인터넷/통신 인프라)가 부족합니다. 이러한 문제를 해결하기 위해 다양한 파트너와 지속적으로 협력하여 고객에게 솔루션을 제공합니다. 궁극적으로 우리는 더 넓은 지역에 서비스를 제공하기 위한 이러한 투자를 통해 전 세계의 더 많은 고객을 돕고 무료 현금 흐름을 창출하는 더 큰 소비자 비즈니스를 구축할 수 있을 것이라고 믿습니다.  지리적 확장을 넘어 우리는 일부 크고 독특한 제품 소매 시장 부문에 걸쳐 고객 서비스를 확장하기 위해 노력해 왔습니다. 식료품은 미국에서만 평균 8000억 달러 규모의 시장 부문이며, 평균 가구 쇼핑은 주당 3-4회입니다. Amazon은 거의 20년 동안 다소 특이하지만 중요한 식료품 사업을 구축했습니다. 1980년대에 다른 대량 상인들이 식료품 공간에 진입한 방식과 유사하게 우리는 종이 제품, 통조림 및 박스 식품, 사탕 및 스낵, 애완 동물 관리, 건강 및 퍼스널 케어, 뷰티. 그러나 동일한 카테고리에 대해 일반적인 슈퍼마켓의 30K에 비해 300만 개 이상의 항목을 제공합니다. 현재 온라인 배송 서비스 비용을 감안할 때 지금까지 우리는 더 큰 팩 크기에도 초점을 맞췄습니다. 우리는 식료품 사업의 규모와 성장에 만족하지만 오늘날보다 더 많은 고객의 식료품 요구 사항에 부응하고자 합니다. 이를 위해서는 대부분의 식료품 쇼핑이 여전히 물리적 장소에서 발생한다는 점을 감안할 때 더 넓은 물리적 매장 공간이 필요합니다. Whole Foods Market은 40년 전에 자연 및 유기농 전문 식료품점 개념을 개척했습니다. 오늘날 건강하고 지속 가능한 식품에 대한 기준을 지속적으로 높이는 대규모 성장 사업입니다. 지난 1년 동안 우리는 비즈니스에 대한 투자를 계속하면서 수익성을 개선하기 위한 변화도 시도했습니다. Whole Foods는 고무적인 길을 가고 있지만 실제 식료품에 더 큰 영향을 미치려면 광범위하게 확장할 가치가 있다고 생각하는 대량 식료품 형식을 찾아야 합니다. Amazon Fresh는 우리가 몇 년 동안 실험해 온 브랜드이며 Amazon 규모에 적합한 대량 식료품 형식을 식별하고 구축하기 위해 열심히 노력하고 있습니다. 식료품은 Amazon의 큰 성장 기회입니다.  아마존 비즈니스는 우리의 전자상거래 및 물류 역량이 이 대규모 시장 부문을 추구할 수 있는 좋은 위치를 차지하는 투자의 또 다른 예입니다. Amazon Business를 사용하면 기업, 지방 자치 단체 및 조직이 사무용품 및 기타 대량 품목과 같은 제품을 쉽고 저렴하게 조달할 수 있습니다. 경제의 일부 영역이 지난 몇 년 동안 어려움을 겪었지만 아마존 비즈니스는 번창했습니다. 왜? 팀은 선택, 가치 및 편의성을 비즈니스 조달 설정으로 전달하고 고객의 의견을 지속적으로 듣고 고객을 대신하여 혁신한다는 의미를 번역했기 때문입니다. 일부 사람들은 Amazon Business에 대해 들어본 적이 없지만 비즈니스 고객은 Amazon Business를 좋아합니다. Amazon Business는 2015년에\n",
      "\n",
      "시작되었으며 현재 연간 총 매출이 약 350억 달러에 이릅니다. 전 세계 Fortune 100대 기업 중 96개 기업을 포함하여 600만 명 이상의 활성 고객이 Amazon Business의 원스톱 쇼핑, 실시간 분석 및 수억 개의 비즈니스 용품에 대한 광범위한 선택을 즐기고 있습니다. 우리는 지금까지 가능한 것의 극히 일부에 불과하다고 믿으며 비즈니스 고객이 필요로 하고 원한다고 말하는 기능을 계속해서 구축할 계획입니다.  많은 브랜드와 판매자가 아마존 마켓플레이스에서 제품을 성공적으로 판매하고 있지만 자체 소비자 직접 웹사이트를 시작한 많은 브랜드와 판매자도 있습니다. 이러한 판매자의 과제 중 하나는 보기에서 구매로의 전환을 유도하는 것입니다. 우리는 이 문제를 해결하기 위해 Buy with Prime을 개발했습니다. Prime으로 구매하면 타사 브랜드 및 판매자가 자체 웹사이트에서 대규모 Amazon Prime 멤버십에 제품을 제공하고 해당 고객에게 Amazon 계정을 통해 빠른 무료 프라임 배송 및 원활한 결제를 제공할 수 있습니다. Buy with Prime은 Amazon Pay 및 Fulﬁllment by Amazon을 통해 Amazon에서 제품 보관, 피킹, 포장, 배송, 결제 및 모든 반품을 처리하는 등 판매자에게 몇 가지 추가 혜택을 제공합니다. Buy with Prime은 최근 모든 미국 판매자에게 제공되었습니다. 지금까지 Buy with Prime은 타사 쇼핑 사이트에서 구매자 전환을 평균 25% 증가시켰습니다. 가맹점은 더 많은 판매를 전환하고 이러한 배송을 더 쉽게 이행할 수 있다는 사실에 흥분하고 있으며, 프라임 회원은 더 많은 목적지에서 프라임 혜택을 사용할 수 있다는 점에 만족하고 있으며 프라임으로 구매를 통해 더 많은 웹에서 쇼핑 경험을 개선할 수 있습니다.  국제적으로 확장하고, 아직 아마존의 초기 단계인 대규모 소매 시장 부문을 추구하고, 판매자가 자신의 웹사이트에서 보다 효과적으로 판매할 수 있도록 돕기 위해 우리의 고유한 자산을 사용하는 것은 우리에게 어느 정도 자연스러운 확장입니다. 핵심 비즈니스에서 더 멀리 떨어져 있지만 고유한 기회가 있는 투자도 몇 가지 있습니다. 2003년에는 AWS가 전형적인 예였습니다. 2023년에는 Amazon Healthcare와 Kuiper가 잠재적인 아날로그입니다.  의료 분야에서 우리의 초기 노력은 전자 상거래에서 크게 벗어난 것처럼 느껴지지 않는 약국에서 시작되었습니다. 수년 동안 Amazon 고객은 현재 공급자에 대한 불만이 커지면서 언제 온라인 약국을 제공할지 물었습니다. 2020년에 출시된 Amazon Pharmacy는 Prime 회원에게 투명한 가격, 손쉬운 리필 및 비용 절감을 제공하는 풀 서비스 온라인 약국입니다. 비즈니스는 빠르게 성장하고 있으며 혁신을 계속하고 있습니다. 예를 들어 Amazon Pharmacy는 최근 RxPass를 출시했습니다. RxPass는 매월 5달러의 정액 요금으로 Prime 회원이 고혈압, 위산 역류 및 불안과 같은 수십 가지 일반적인 조건에 필요한 적격 처방약을 원하는 만큼 받을 수 있습니다. . 그러나 고객은 Amazon이 비효율적이고 만족스럽지 못한 광범위한 의료 경험에 대한 더 나은 대안을 제공하기를 바라는 강한 열망을 계속 표명했습니다. 우리는 일차 진료가 환자 여정에서 널리 퍼진 첫 번째 중지이기\n",
      "\n",
      "때문에 시작하기로 결정했습니다. 우리는 Amazon Care와 같은 일부 초기 Amazon 실험을 포함하여 기존 환경을 광범위하게 평가하고 연구했습니다. 이 과정에서 우리는 One Medical의 환자 중심 경험이 우리의 미래 사업을 구축하기 위한 훌륭한 기반임을 확인했습니다. 그리고 2022년 7월에 One Medical 인수를 발표했습니다. 고객님들이 원메디컬에 대해 좋아하는 요소가 몇가지 있습니다. 환자가 채팅이나 화상 회의를 통해 의사와 문제를 쉽게 논의할 수 있는 환상적인 디지털 앱이 있습니다. 실제 방문이 필요한 경우 One Medical은 미국 전역의 도시에 사무실을 두고 환자가 당일 또는 익일 약속을 예약할 수 있습니다. One Medical은 각 도시의 전문의와 관계를 맺고 있으며 지역 병원 시스템과 긴밀히 협력하여 전문의를 쉽게 만날 수 있으므로 One Medical 회원은 필요할 때 이러한 리소스에 신속하게 액세스할 수 있습니다. 앞으로 우리는 One Medical과 Amazon이 고객을 위한 1차 진료의 모습을 변화시키기 위해 계속해서 함께 혁신할 것이라고 굳게 믿습니다.  Kuiper는 Amazon이 고객 요구 사항이 높은 영역에서 장기적으로 고객을 위해 혁신한 또 다른 예입니다. Kuiper에 대한 우리의 비전은 현재 없는 전 세계에 고품질 광대역 인터넷 서비스를 제공하는 저궤도 위성 시스템을 만드는 것입니다. 인터넷에 안정적으로 액세스할 수 없는 수억 개의 가정과 기업이 있습니다. 사람들이 온라인 교육 과정을 수강하고, 금융 서비스를 사용하고, 사업을 시작하고, 쇼핑을 하고, 엔터테인먼트를 즐기는 것부터 서비스 범위, 효율성 및 운영을 개선하는 기업 및 정부에 이르기까지 안정적인 연결로 무엇을 할 수 있을지 상상해 보십시오. Kuiper는 접근성뿐만 아니라 경제성도 제공할 것입니다. 우리 팀은 액세스 장벽을 낮출 저비용 안테나(예: 고객 단말기)를 개발했습니다. 우리는 최근 오버헤드를 통과하는 위성과 통신할 새 터미널을 공개했으며 표준 주거용 버전을 개당 $400 미만으로 생산할 수 있을 것으로 기대합니다. 그것들은 작습니다: 11인치 정사각형, 1인치 두께, 마운팅 브래킷을 제외하고 무게는 5파운드 미만이지만 초당 최대 400메가비트의 속도를 제공합니다. 그리고 Amazon에서 설계한 베이스밴드 칩으로 구동됩니다. 우리는 올해 전체 엔드-투-엔드 통신 네트워크를 테스트하기 위해 두 개의 프로토타입 위성을 발사할 준비를 하고 있으며 2024년에는 상용 고객과 함께 베타 테스트를 할 계획입니다. 지금까지 Kuiper에 대해 공유한 내용에 대한 고객 반응은 매우 긍정적이며 Kuiper가 Amazon에 매우 큰 잠재적 기회를 제공한다고 믿습니다. 또한 처음에는 자본 집약적이라는 점에서 AWS와 몇 가지 유사점을 공유하지만 잠재 소비자, 기업 및 정부 고객 기반이 넓고 상당한 수익 및 영업 이익 잠재력이 있으며 기술 및 창의적 능력을 갖춘 회사가 상대적으로 적다는 점에서 AWS와 유사합니다. 그것을 추구하는 투자 가설로.  제가 언급할 마지막 투자 영역은 Amazon이 앞으로 수십 년 동안 모든 비즈니스 영역에서 발명할 수 있도록 설정하는 핵심이며 대규모 언어 모델(\"LLM\") 및 생성 AI입니다. 머신 러닝은 수십 년 동안 유망한 기술이었지만 기업에서 널리 사용되기 시작한 것은 불과 5~10년 전입니다. 이러한\n",
      "\n",
      "변화는 그 어느 때보다 낮은 가격으로 더 많은 양의 컴퓨팅 용량에 대한 액세스를 포함하여 몇 가지 요인에 의해 주도되었습니다. Amazon은 25년 동안 기계 학습을 광범위하게 사용해 왔으며 개인화된 전자 상거래 권장 사항부터 주문 처리 센터 선택 경로, Prime Air용 드론, Alexa, AWS가 제공하는 많은 기계 학습 서비스(AWS가 가장 광범위한 기계를 보유한 곳) 모든 클라우드 공급자의 학습 기능 및 고객 기반). 보다 최근에는 GeneraTve AI라고 하는 새로운 형태의 기계 학습이 등장하여 기계 학습 채택을 크게 가속화할 것이라고 약속합니다. 제너레이티브 AI는 매우 큰 언어 모델(최대 천억 개의 매개변수에 대해 훈련되고 계속 증가하고 있음)을 기반으로 하며 광범위한 데이터 세트에 걸쳐 매우 일반적이고 광범위한 리콜 및 학습 기능을 갖추고 있습니다. 우리는 한동안 자체 LLM에 대해 작업해 왔으며 이것이 거의 모든 고객 경험을 변화시키고 개선할 것이라고 믿으며 모든 소비자, 판매자, 브랜드 및 제작자 경험에 걸쳐 이러한 모델에 계속해서 상당한 투자를 할 것입니다. 또한 AWS에서 수년간 해왔듯이 모든 규모의 회사가 제너레이티브 AI를 활용할 수 있도록 이 기술을 민주화하고 있습니다. AWS는 Trainium 및 InferenTa에서 가장 가격 대비 성능이 뛰어난 기계 학습 칩을 제공하므로 소규모 및 대규모 기업이 프로덕션 환경에서 LLM을 교육하고 실행할 수 있습니다. 우리는 회사가 다양한 LLM 중에서 선택하고 고객이 사용하는 데 익숙한 모든 AWS 보안, 개인 정보 보호 및 기타 기능을 갖춘 애플리케이션을 구축할 수 있도록 합니다. 또한 실시간으로 코드 제안을 생성하여 개발자 생산성을 혁신하는 AWS의 CodeWhisperer와 같은 애플리케이션을 제공하고 있습니다. LLM과 GeneraTve AI가 그렇게 변혁적일 것이라고 생각하기 때문에 전체 편지를 쓸 수 있지만 향후 편지로 남겨두겠습니다. LLM과 GeneraTve AI가 고객, 주주 및 Amazon에게 큰 문제가 될 것이라고 가정해 보겠습니다.  그래서 마지막으로 저는 우리가 이 도전적인 거시경제 시대에 진입했을 때보다 더 강력한 위치에서 등장할 것이라고 낙관합니다. 여기에는 몇 가지 이유가 있으며 위에서 많은 이유를 언급했습니다. 그러나 우리의 엄청난 미래 기회를 강조하는 두 가지 비교적 간단한 통계가 있습니다. 우리는 2022년에 4,340억 달러 규모의 소비자 비즈니스를 보유하고 있지만, 전 세계 소매업의 전체 시장 부문 점유율의 대부분은 여전히 물리적 매장에 있습니다(약 80%). 그리고 2022년에 AWS 수익이 800억 달러이고 글로벌 IT 지출의 약 90%가 여전히 온프레미스에 있지만 아직 클라우드로 마이그레이션하지 않는 글로벌 IT 지출에 대한 유사한 이야기입니다. 우리가 이미 보고 있는 것처럼 이러한 방정식이 꾸준히 역전됨에 따라 우리는 선도적인 고객 경험, 끊임없는 발명, 고객 중심 및 노력이 향후 몇 년 동안 상당한 성장을 가져올 것이라고 믿습니다. 그리고 물론 여기에는 Amazon에서 추구하는 다른 비즈니스와 경험이 포함되지 않으며 모두 아직 초기 단계입니다.  저는 우리의 최고의 날이 우리 앞에 와 있다고 굳게 믿으며, 그렇게 되도록 Amazon의 팀원들과 협력하기를 기대합니다.\n",
      "\n",
      "위의 내용을 Korean으로 bullet point 3개로 요약합니다:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " 아마존의 연례 주주 서한 내용을 3개의 한국어 bullet point로 요약하면 다음과 같습니다:  - 아마존은 소매, AWS, 광고 등 주요 사업 분야에서 여전히 성장 잠재력이\n",
      "크다고 보며 미개척 시장을 계속 확장할 것  - 식료품, 의료, 위성 인터넷 서비스 등 새로운 사업 영역에 진출하여 기회를 모색할 것  - 기계 학습, 대규모 언어 모델 등\n",
      "신기술에 계속 투자하여 고객 경험과 비즈니스를 혁신해 나갈 것\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "import textwrap\n",
    "\n",
    "\n",
    "stuff_prompt_template = \"{text}\\n\\n위의 내용을 Korean으로 bullet point 3개로 요약합니다:\"\n",
    "stuff_prompt = PromptTemplate(template=stuff_prompt_template, input_variables=[\"text\"])\n",
    "\n",
    "chain = load_summarize_chain(llm, chain_type=\"stuff\", prompt=stuff_prompt,verbose = True)\n",
    "\n",
    "output_summary = chain.run(docs) \n",
    "\n",
    "wrapped_text = textwrap.fill(output_summary, width=100)\n",
    "print(wrapped_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feec81b9-89a8-4f1b-bc11-d12c873099ca",
   "metadata": {},
   "source": [
    "## REFINE\n",
    "\n",
    "'Refine(정제)' 체인에는 첫 번째 데이터 청크에 대한 초기 프롬프트가 포함되어 출력을 생성합니다. 언어 모델은 이 출력을 다음 문서와 함께 전달하여 새 문서를 기반으로 출력을 다듬습니다.\n",
    "\n",
    "이 반복적인 정제 프로세스는 보다 정확한 요약을 생성하는 데 도움이 됩니다. load_summarize_chain 함수를 사용하여 'refine' 체인을 설정하고 요약된 출력을 얻습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab0c6509-cc3e-458f-af8b-58f6b56c1554",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RefineDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mCEO로서 두 번째 연례 주주 서한을 작성하기 위해 자리에 앉았을 때 저는 Amazon의 앞날에 대해 낙관적이고 활력을 얻었습니다. 2022년은 최근 기억에 있어 어려운 거시경제적 해 중 하나이고 우리 자체의 운영상의 어려움에도 불구하고 우리는 여전히 수요를 늘릴 방법을 찾았습니다(팬데믹 전반기에 경험한 전례 없는 성장에 더해). 우리는 장단기적으로 고객 경험을 의미 있게 개선하기 위해 대규모 사업을 혁신했습니다. 그리고 고객, 주주 및 직원을 위해 Amazon의 미래를 바꿀 수 있다고 믿는 장기 투자를 계속 유지하면서 투자 결정과 앞으로 나아갈 방법에 중요한 조정을 했습니다.  작년에 이례적인 수의 동시 도전 과제가 있었지만 현실은 유능하고 자금이 충분한 경쟁자가 많은 크고 역동적인 글로벌 시장 부문에서 운영하는 경우(아마존이 모든 비즈니스를 운영하는 조건) 조건이 오랫동안 정체되어 있는 경우는 드뭅니다.  제가 Amazon에 근무한 25년 동안 끊임없는 변화가 있었고 그 중 대부분은 우리가 스스로 시작했습니다. 내가 1997년에 Amazon에 입사했을 때 우리는 1996년에 1,500만 달러의 매출을 올렸고, 도서 전용 소매업체였으며, 제3자 시장이 없었고, 미국 내 주소로만 배송되었습니다. 오늘날 Amazon은 단위 판매의 60%를 차지하고 전 세계 거의 모든 국가의 고객에게 도달하는 활기찬 타사 판매자 에코시스템을 통해 상상할 수 있는 거의 모든 물리적 및 디지털 소매 품목을 판매합니다. 마찬가지로 클라우드에서 일련의 기술 인프라 서비스를 중심으로 비즈니스를 구축하는 것은 AWS를 추구하기 시작한 2003년에는 분명하지 않았으며 2006년 첫 서비스를 출시했을 때도 마찬가지였습니다. 거의 모든 책을 60초 안에 손끝에서 볼 수 있습니다 2007년 Kindle을 출시했을 때 가벼운 디지털 리더에 저장하고 검색할 수 있다는 것은 아직 \"사물\"이 아니었고 Alexa(2014년 출시)와 같이 액세스하는 데 사용할 수 있는 음성 기반 개인 비서도 아니었습니다. 엔터테인먼트, 스마트 홈 제어, 쇼핑 및 모든 종류의 정보 검색.  또한 거시 경제 상황이나 운영 비효율성으로 인해 우리에게 새로운 과제가 제시된 경우도 있었습니다. 예를 들어 2001년 닷컴 폭락 당시 우리는 연휴 기간 동안 재고를 구매하기 위해 신용장을 확보해야 했고 비즈니스의 더 나은 수익성을 제공하기 위해 비용을 합리화해야 했지만 여전히 우리가 노력하고 있던 장기적인 고객 경험과 비즈니스를 우선시했습니다. 빌드(기억한다면, 우리는 실제로 2001년 그 미미한 기간 동안 대부분의 범주에서 가격을 낮췄습니다). 2008-2009년에 모기지 담보 증권 금융 위기로 촉발된 경기 침체를 견디면서 이런 종류의 균형을 다시 보았습니다. 우리는 매장 비즈니스의 비용 구조와 효율성을 관리하기 위해 몇 가지 조치를 취했지만, 주주에게 강력한 수익을 제공하는 실질적인 미래 비즈니스가 될 수 있다고 생각하는 고객 경험에 대한 투자와 이러한 합리화의 균형을 맞췄습니다. 2008년에 AWS는 여전히 상당히 작고 신생 기업이었습니다. 우리는 우리가 무언가를 하고 있다는 것을 알고 있었지만\n",
      "\n",
      "위의 내용을 Korean으로 요약합니다:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m여전히 상당한 자본 투자가 필요했습니다. 회사 안팎에서는 아마존(당시 주로 온라인 소매업체로 알려짐)이 클라우드 컴퓨팅에 많은 투자를 하는 이유에 대해 의문을 제기하는 목소리가 있었습니다. 그러나 우리는 미래에 고객과 아마존을 위해 많은 가치를 창출할 수 있는 특별한 것을 발명하고 있다는 것을 알고 있었습니다. 우리는 잠재적 경쟁자보다 먼저 출발했습니다. 무엇보다 우리는 혁신 속도를 가속화하고 싶었습니다. 우리는 AWS에 계속 투자하기로 장기적인 결정을 내렸습니다. 15년 후 AWS는 이제 신생 기업에서 다국적 기업, 공공 부문 조직에 이르기까지 고객이 기술 인프라를 관리하는 방식을 변화시킨 강력한 수익성을 갖춘 연간 매출 850억 달러 규모의 기업이 되었습니다. 2008-2009년 기간 동안 AWS에 대한 투자를 늦추었다면 Amazon은 다른 회사가 되었을 것입니다.  변화는 항상 가까이에 있습니다. 때로는 적극적으로 초대하고 때로는 그냥 노크합니다. 그러나 그것이 오는 것을 보았을 때, 그것을 받아들여야 합니다. 그리고 장기간에 걸쳐 이를 잘 수행하는 회사는 일반적으로 성공합니다. 나는 우리 팀이 우리 앞에 보이는 변화에 대응하는 방식이 마음에 들기 때문에 우리의 미래 전망에 대해 낙관적입니다.  지난 몇 달 동안 우리는 회사 전체를 비즈니스별로, 발명별로 자세히 살펴보고 각 이니셔티브의 장기적인 잠재력에 대해 충분한 수익, 운영 수입, 무료 현금 흐름, 투자 자본 수익률. 경우에 따라 특정 비즈니스를 폐쇄하게 되었습니다. 예를 들어 우리는 서점 및 4스타 매장과 같은 물리적 매장 개념 추구를 중단하고 Amazon Fabric 및 Amazon Care 노력을 중단했으며 의미 있는 수익을 얻을 수 있는 경로가 보이지 않는 일부 최신 장치에서 전환했습니다. 다른 경우에는 우리가 기대했던 수익을 내지 못하는 일부 프로그램(예: $35 이상의 모든 온라인 식료품 주문에 대한 무료 배송)을 살펴보고 수정했습니다. 우리는 또한 리소스를 어디에 사용할지 우선 순위를 재지정했고, 결국 27,000개의 회사 역할을 제거하는 어려운 결정을 내렸습니다. 전체 비용을 합리화하기 위해 지난 몇 개월 동안 수행한 다른 변경 사항이 많이 있으며 대부분의 리더십 팀과 마찬가지로 비즈니스에서 보고 있는 사항을 계속 평가하고 적응적으로 진행할 것입니다.  우리는 또한 팀으로 어떻게 협력하고 있는지 열심히 살펴보았고 회사 직원들에게 5월부터 일주일에 최소 3일은 사무실로 돌아올 것을 요청했습니다. 팬데믹 기간 동안 우리 직원들은 집에서 일하기 위해 집결했으며 예상치 못한 상황에 대처하기 위해 가능한 모든 일을 했습니다. 그것은 인상적이었고 저는 우리의 집단적 팀이 고객, 지역 사회 및 비즈니스에 대한 전례 없는 도전을 극복하기 위해 함께 모인 방식이 자랑스럽습니다. 그러나 우리는 이것이 최선의 장기적 접근 방식이라고 생각하지 않습니다. 우리는 함께 일하고 직접 서로에게서 배울 때 협업과 발명이 더 쉽고 효과적이라는 것을 확신하게 되었습니다. 서로의 아이디어에 대한 에너지와 반복은 더 자유롭게 발생하며 최고의 Amazon 발명품 중 다수는 사람들이 회의 후 뒤에 남아 화이트보드에서\n",
      "\n",
      "위의 내용을 Korean으로 최종적으로 요약합니다:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m아이디어를 검토하거나 회의에서 돌아오는 길에 대화를 계속하면서 획기적인 순간을 맞이했습니다. , 또는 다른 생각으로 그날 늦게 팀원의 사무실에 들르는 것. 발명은 종종 지저분합니다. 그것은 방황하고 구불 구불하고 마리 네이드합니다. 뜻밖의 상호 작용이 도움이 되며, 가상으로 하는 것보다 직접 만나는 것이 더 많습니다. 또한 우리가 대부분의 시간을 함께 사무실에 있고 동료들에게 둘러싸여 있을 때 우리 문화를 배우고, 모델링하고, 연습하고, 강화하는 것이 훨씬 더 쉽습니다. 혁신과 우리 고유의 문화는 회사로서 처음 29년 동안 매우 중요했으며 다음 29년에도 마찬가지로 그렇게 될 것으로 기대합니다.  우리가 계속해서 해결해야 할 중요한 문제는 매장 주문 처리 네트워크에서 서비스를 제공하는 데 드는 비용(예: Amazon에서 고객에게 제품을 제공하는 비용)이 증가하는 것입니다. 비용 및 배송 속도.  팬데믹 초기에는 많은 오프라인 매장이 문을 닫았고, 우리 소비자 비즈니스는 놀라운 속도로 성장하여 연간 매출이 2019년 2,450억 달러에서 2022년 4,340억 달러로 증가했습니다. 이는 주문 처리 센터 공간을 두 배로 늘려야 함을 의미했습니다. 지난 25년 동안 우리가 구축한 운송 네트워크를 현재 UPS 크기의 라스트 마일 운송 네트워크 구축을 크게 가속화했습니다(항목이 장거리를 통과해야 할 때 효율성과 속도를 지원하기 위한 새로운 분류 센터 네트워크 포함). 약 2년의 시간 동안. 이것은 쉬운 일이 아니었고 수십만 명의 아마존 사람들이 이것을 실현하기 위해 매우 열심히 일했습니다. 그러나 이러한 변화의 속도와 규모로 인해 의도한 생산성을 얻기 위해서는 많은 최적화가 필요했습니다. 지난 몇 달 동안 우리는 주문 처리 센터 및 운송 네트워크의 모든 프로세스 경로를 면밀히 조사하고 수십 가지 프로세스 및 메커니즘을 재설계하여 지난 몇 분기 동안 꾸준한 생산성 향상과 비용 절감을 가져왔습니다. 해야 할 일이 더 많지만 우리의 궤적과 우리 앞에 있는 의미 있는 상승세에 만족합니다.  우리는 또한 앞으로 수년 동안 더 낮은 비용과 더 빠른 속도를 제공할 수 있도록 더 큰 구조적 변화를 만들기 위해 이 기회를 잡았습니다. 좋은 예는 미국 주문 처리 네트워크가 어떻게 구성되어 있는지 재평가하는 것입니다. 최근까지 아마존은 미국 전역에 퍼져 있는 주문 처리 센터의 재고를 분배하는 하나의 미국 전국 주문 처리 네트워크를 운영했습니다. 지역 주문 처리 센터에 고객이 주문한 제품이 없으면 결국 다른 지역에서 배송하게 되므로 더 많은 비용이 들고 배송 시간이 늘어납니다. 이 문제는 주문 처리 네트워크가 지난 몇 년 동안 수백 개의 추가 노드로 확장되어 더 많은 위치에 재고를 분배하고 주문 처리 센터와 배송 스테이션 노드를 효율적으로 연결하는 복잡성이 증가함에 따라 더욱 두드러졌습니다. 작년에 우리는 재고 배치 전략을 재설계하고 더 큰 주문 처리 센터 공간을 활용하여 전국 주문 처리 네트워크에서 지역화된 네트워크 모델로 이동하기 시작했습니다. 우리는 더 작은 지리적 영역에 8개의 상호 연결된 지역을 만들기 위해\n",
      "\n",
      "위의 내용을 Korean으로 최종적으로 요약합니다:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m상당한 내부 변경(예: 배치 및 물류 소프트웨어, 프로세스, 물리적 운영)을 수행했습니다. 이러한 각 지역은 대부분 자급자족 방식으로 운영할 수 있는 광범위하고 적절한 선택권을 가지고 있으며 필요할 때 여전히 전국적으로 배송할 수 있습니다. 가장 의미 있고 힘든 작업 중 일부는 이 많은 양의 인프라 간의 연결을 최적화하는 데 있었습니다. 또한 적시에 올바른 지역에 올바른 재고를 보유할 수 있도록 국가의 여러 지역에 있는 고객이 필요로 하는 것이 무엇인지 더 잘 예측하기 위해 고급 기계 학습 알고리즘을 지속적으로 개선하고 있습니다. 최근에 이 지역 출시를 완료했으며 초기 결과가 마음에 듭니다. 이동 거리가 짧다는 것은 서비스 비용이 낮아지고 환경에 미치는 영향이 줄어들며 고객이 주문을 더 빨리 받는 것을 의미합니다. 후자의 경우 더 많은 익일 배송 및 당일 배송을 보게 되어 기쁩니다. 2023년에는 프라임 배송 속도가 가장 빨라질 것입니다. 전반적으로 우리는 비용 절감, 배송 감소 계획에 대해 확신을 가지고 있습니다. 건전한 운영 마진으로 의미 있게 더 큰 소매 사업을 구축하십시오.  AWS는 연간 850억 달러의 수익을 내고 있으며 아직 채택 곡선 초기 단계에 있지만 장기적으로 고객에게 가장 중요한 것에 집중하는 것이 중요한 시점에 있습니다. 2022년에 620억 달러의 수익 기반으로 전년 대비 29%(\"YoY\") 성장했음에도 불구하고 AWS는 기업들이 현재의 어려운 거시 경제 상황을 고려할 때 지출에 더욱 신중을 기하고 있기 때문에 단기적인 역풍에 직면해 있습니다. 일부 회사는 이 어려운 시기에 고객으로부터 최대한 많은 돈을 뽑아낼 수 있는 방법에 집착할 수 있지만 장기적으로 고객이 원하는 것도 고객을 위한 최선도 아니므로 우리는 다른 방식을 취하고 있습니다. AWS와 클라우드 컴퓨팅의 많은 이점 중 하나는 비즈니스가 성장하면 원활하게 확장할 수 있다는 것입니다. 반대로 비즈니스 계약이 체결되면 해당 용량을 반환하고 비용 지불을 중단하도록 선택할 수 있습니다. 이러한 탄력성은 클라우드에 고유하며 자체 온프레미스 데이터 센터, 서버 및 네트워킹 장비에 이미 값비싼 자본 투자를 한 경우에는 존재하지 않습니다. AWS에서는 모든 비즈니스와 마찬가지로 한 분기 또는 1년 동안 최적화하려고 하지 않습니다. 우리는 우리 모두보다 오래 지속되는 고객 관계(및 비즈니스)를 구축하기 위해 노력하고 있습니다. 그 결과 AWS 영업 및 지원 팀은 고객이 이 불확실한 경제를 더 잘 헤쳐나갈 수 있도록 AWS 지출을 최적화하는 데 많은 시간을 할애하고 있습니다. 이러한 AWS 고객 중 다수는 비용 최적화만큼 비용 절감이 아니라 리소스를 가져와 계획 중인 새롭고 독창적인 새로운 고객 경험에 적용할 수 있다고 말합니다. 고객은 이러한 고객 중심의 장기적인 접근 방식을 높이 평가했으며 고객과 AWS 모두에게 좋은 징조가 될 것이라고 생각합니다.  이러한 단기 역풍이 우리의 성장률을 약화시키는 동안 우리는 AWS에서 볼 수 있는 많은 기본 사항을 좋아합니다. 우리의 새로운 고객 파이프라인은 활성 마이그레이션과 마찬가지로 강력합니다. 많은 기업이 이와 같은 비연속 기간을 사용하여 뒤로 물러나 전략적으로 변경하려는 사항을 결정합니다. 자체 인프라 관리를 거부하고 민첩성, 혁신, 비용 절감 효과를 누리기 위해\n",
      "\n",
      "위의 내용을 Korean으로 최종적으로 요약합니다:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mAWS로 이전하는 것을 선호하는 기업이 점점 더 많아지고 있습니다. 효율성 및 보안 이점. 그리고 고객에게 가장 중요한 것은 AWS가 계속해서 새로운 기능을 신속하게 제공하고(2022년에 출시된 3,300개 이상의 새로운 기능 및 서비스) 가능한 것을 변화시키는 장기적인 발명에 투자한다는 것입니다.  칩 개발이 좋은 예입니다. 작년 편지에서 저는 Graviton이라는 범용 CPU 프로세서에 대한 투자에 대해 언급했습니다. Graviton2 기반 컴퓨팅 인스턴스는 비슷한 최신 세대 x86 기반 인스턴스보다 최대 40% 더 나은 가격 대비 성능을 제공합니다. 2022년에는 Graviton2 프로세서보다 25% 향상된 성능을 제공하는 Graviton3 칩을 제공했습니다. 또한 기계 학습 채택이 지속적으로 가속화됨에 따라 고객은 저렴한 GPU(기계 학습에 가장 일반적으로 사용되는 칩)를 원했습니다. AWS는 몇 년 전부터 기계 학습 훈련 및 추론을 위한 이러한 특수 칩에 투자하기 시작했습니다(추론은 기계 학습 모델이 제공하는 예측 또는 답변입니다). 우리는 2022년에 첫 번째 교육용 칩(\"Trainium\")을 제공했습니다. 가장 일반적인 기계 학습 모델의 경우 Trainium 기반 인스턴스는 GPU 기반 인스턴스보다 최대 70% 더 저렴한 비용으로 최대 140% 더 빠릅니다. 대부분의 회사는 아직 교육 단계에 있지만 대규모 생산으로 전환되는 모델을 개발함에 따라 모델은 주기적으로 교육되는 반면 추론은 관련 응용 프로그램으로 항상 발생하기 때문에 대부분의 비용이 추론에 있음을 알게 될 것입니다. 행사중입니다. 우리는 2019년에 첫 번째 추론 칩(\"InferenTa\")을 출시했으며 Amazon과 같은 회사는 이미 1억 달러 이상의 자본 비용을 절감했습니다. 방금 출시된 InferenTa2 칩은 첫 번째 InferenTa 프로세서보다 최대 4배 더 높은 처리량과 10배 더 짧은 대기 시간을 제공합니다. 기계 학습의 엄청난 성장으로 인해 고객은 훨씬 저렴한 비용으로 AWS의 교육 및 추론 칩을 사용하여 훨씬 더 많은 작업을 수행할 수 있습니다. 여기서 혁신이 거의 완료되지 않았으며 이 장기 투자는 고객과 AWS 모두에게 유익한 것으로 입증되어야 합니다. AWS는 아직 진화의 초기 단계에 있으며 향후 10년 동안 비정상적으로 성장할 가능성이 있습니다.  마찬가지로 높은 잠재력을 지닌 Amazon의 광고 비즈니스는 브랜드에 고유한 효과를 발휘하며, 이는 계속해서 빠른 속도로 성장하는 이유 중 하나입니다. 선반 공간, 엔드 캡, 원형 배치를 판매하는 물리적 소매업체의 광고 사업과 유사하게, 당사가 후원하는 제품 및 브랜드 제품은 10년 이상 아마존 쇼핑 경험의 필수적인 부분이었습니다. 그러나 실제 소매업체와 달리 Amazon은 쇼핑 행동에 대해 알고 있는 것과 기계 학습 알고리즘에 대한 우리의 매우 깊은 투자를 고려할 때 이러한 후원 제품을 고객이 검색하는 것과 관련이 있도록 조정할 수 있습니다. 이는 고객에게 더 유용한 광고로 이어집니다. 결과적으로 브랜드에 더 나은 성능을 제공합니다. 이것이 우리의 광고 수익이 지난 2022년 4분기에 23% YoY , 310억 달러 수익 기반에서 2022년에 전체적으로 25% YoY 성장을 지속한 이유 중 하나입니다. 몇 분기.\n",
      "\n",
      "위의 내용을 Korean으로 최종적으로 요약합니다:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m우리는 광고주가 자신의 브랜드를 구축할 수 있는 최고의 장소가 되기 위해 노력합니다. 우리는 그 임무를 달성하는 데 도움이 될 장단기 기회를 가지고 있습니다. 우리는 광고 선택 알고리즘을 계속 연마하기 위해 기계 학습에 많은 투자를 계속하고 있습니다. 지난 몇 년 동안 우리는 포괄적이고 유연하며 내구성 있는 계획 및 측정 솔루션을 구축하는 데 투자하여 마케터에게 광고 효과에 대한 더 큰 통찰력을 제공했습니다. 예를 들어 Amazon MarkeTng Cloud(\"AMC\")가 있습니다. AMC는 광고주가 개인정보를 보호하는 방식으로 자사 및 제3자 입력 범위에서 맞춤 잠재고객 및 캠페인 분석을 실행하여 광고 및 비즈니스 통찰력을 생성하여 광범위한 마케팅 및 판매 전략. 광고 팀과 AWS 팀은 기업이 데이터를 AWS에 저장하고, Amazon 및 기타 타사 데이터 소스와 함께 AMC에서 안전하게 운영하고, AWS에서 분석을 수행하고, Amazon 또는 타사 게시자에서 광고를 활성화할 수 있는 옵션을 갖도록 협력했습니다. Amazon 수요 측 플랫폼을 통해. 고객은 이러한 공동 기능을 정말 좋아합니다. 우리는 또한 광고를 비디오, 라이브 스포츠, 오디오 및 식료품 제품에 신중하게 통합할 미래의 기회를 봅니다. 우리는 브랜드가 적절한 고객과 독특하게 소통하고 비즈니스의 이 부분을 성장시킬 수 있도록 계속 열심히 노력할 것입니다.  격동의 시기에 기존 대기업에만 집중하고 다양한 차원에서 고객을 지원하는 지속 가능하고 오래 지속되며 성장하는 회사를 구축하려는 유혹이 있지만 장기적인 고객 경험을 개발하고 작업하는 것을 멈출 수는 없습니다. 고객과 회사에 의미 있는 영향을 미칠 수 있습니다.  새로운 투자 기회를 모색할 때 다음과 같은 몇 가지 질문을 스스로에게 던집니다.  우리가 성공한다면 규모가 크고 투자 자본에 대한 합리적인 수익을 낼 수 있을까요? 오늘 기회가 잘 제공되고 있습니까? 차별화된 접근 방식이 있습니까? 그리고, 우리는 그 분야에 대한 역량을 가지고 있습니까? 그렇지 않다면 빨리 획득할 수 있습니까? 이러한 질문에 대한 답변이 마음에 들면 투자할 것입니다. 이 과정은 간단해 보이는 일부 확장과 일부 사람들이 처음에 추측하지 못한 확장으로 이어졌습니다.  가장 초기의 예는 단순히 책을 판매하는 것에서 음악, 비디오, 전자 제품 및 장난감과 같은 범주를 추가하는 것으로 확장하기로 선택한 경우입니다. 그 당시(1998-1999)에는 보편적인 박수갈채를 받지 못했지만 돌이켜보면 꽤 분명한 것 같습니다.  해외 매장 확장에 대해서도 마찬가지입니다. 2022년에 우리의 국제 소비자 부문은 1,180억 달러의 수익을 창출했습니다. 더 크고 확립된 국제 소비자 비즈니스에서 우리는 거시경제 상황 둔화의 영향을 받을 만큼 충분히 큽니다. 그러나 2019-2021년에는 영국의 30%, 독일의 26%, 일본의 21%(FX 영향 제외)의 복합 연간 성장률(“CAGR”)로 큰 규모에서 놀라운 성장을 보였습니다. 지난 몇\n",
      "\n",
      "위의 내용을 Korean으로 최종적으로 요약합니다:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m년 동안 우리는 인도, 브라질, 멕시코, 호주, 다양한 유럽 국가, 중동 및 아프리카 일부를 포함한 새로운 국제 지역에 투자했습니다. 이 새로운 국가들은 시작하고 확장하기 위해 일정량의 고정 투자를 받지만 우리는 그들의 궤도가 마음에 들고 그들의 성장 패턴은 우리가 북미와 우리가 확립한 국제 지역에서 본 것과 유사합니다. 신흥 국가에는 때때로 우리 사업이 의존하는 일부 인프라와 서비스(예: 결제 방법, 운송 서비스 및 인터넷/통신 인프라)가 부족합니다. 이러한 문제를 해결하기 위해 다양한 파트너와 지속적으로 협력하여 고객에게 솔루션을 제공합니다. 궁극적으로 우리는 더 넓은 지역에 서비스를 제공하기 위한 이러한 투자를 통해 전 세계의 더 많은 고객을 돕고 무료 현금 흐름을 창출하는 더 큰 소비자 비즈니스를 구축할 수 있을 것이라고 믿습니다.  지리적 확장을 넘어 우리는 일부 크고 독특한 제품 소매 시장 부문에 걸쳐 고객 서비스를 확장하기 위해 노력해 왔습니다. 식료품은 미국에서만 평균 8000억 달러 규모의 시장 부문이며, 평균 가구 쇼핑은 주당 3-4회입니다. Amazon은 거의 20년 동안 다소 특이하지만 중요한 식료품 사업을 구축했습니다. 1980년대에 다른 대량 상인들이 식료품 공간에 진입한 방식과 유사하게 우리는 종이 제품, 통조림 및 박스 식품, 사탕 및 스낵, 애완 동물 관리, 건강 및 퍼스널 케어, 뷰티. 그러나 동일한 카테고리에 대해 일반적인 슈퍼마켓의 30K에 비해 300만 개 이상의 항목을 제공합니다. 현재 온라인 배송 서비스 비용을 감안할 때 지금까지 우리는 더 큰 팩 크기에도 초점을 맞췄습니다. 우리는 식료품 사업의 규모와 성장에 만족하지만 오늘날보다 더 많은 고객의 식료품 요구 사항에 부응하고자 합니다. 이를 위해서는 대부분의 식료품 쇼핑이 여전히 물리적 장소에서 발생한다는 점을 감안할 때 더 넓은 물리적 매장 공간이 필요합니다. Whole Foods Market은 40년 전에 자연 및 유기농 전문 식료품점 개념을 개척했습니다. 오늘날 건강하고 지속 가능한 식품에 대한 기준을 지속적으로 높이는 대규모 성장 사업입니다. 지난 1년 동안 우리는 비즈니스에 대한 투자를 계속하면서 수익성을 개선하기 위한 변화도 시도했습니다. Whole Foods는 고무적인 길을 가고 있지만 실제 식료품에 더 큰 영향을 미치려면 광범위하게 확장할 가치가 있다고 생각하는 대량 식료품 형식을 찾아야 합니다. Amazon Fresh는 우리가 몇 년 동안 실험해 온 브랜드이며 Amazon 규모에 적합한 대량 식료품 형식을 식별하고 구축하기 위해 열심히 노력하고 있습니다. 식료품은 Amazon의 큰 성장 기회입니다.  아마존 비즈니스는 우리의 전자상거래 및 물류 역량이 이 대규모 시장 부문을 추구할 수 있는 좋은 위치를 차지하는 투자의 또 다른 예입니다. Amazon Business를 사용하면 기업, 지방 자치 단체 및 조직이 사무용품 및 기타 대량 품목과 같은 제품을 쉽고 저렴하게 조달할 수 있습니다. 경제의 일부 영역이 지난 몇 년 동안 어려움을 겪었지만 아마존 비즈니스는 번창했습니다. 왜? 팀은 선택, 가치 및 편의성을 비즈니스 조달 설정으로 전달하고 고객의 의견을 지속적으로 듣고 고객을 대신하여 혁신한다는 의미를 번역했기 때문입니다. 일부 사람들은 Amazon Business에 대해 들어본 적이 없지만 비즈니스 고객은 Amazon Business를 좋아합니다. Amazon Business는 2015년에\n",
      "\n",
      "위의 내용을 Korean으로 최종적으로 요약합니다:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m시작되었으며 현재 연간 총 매출이 약 350억 달러에 이릅니다. 전 세계 Fortune 100대 기업 중 96개 기업을 포함하여 600만 명 이상의 활성 고객이 Amazon Business의 원스톱 쇼핑, 실시간 분석 및 수억 개의 비즈니스 용품에 대한 광범위한 선택을 즐기고 있습니다. 우리는 지금까지 가능한 것의 극히 일부에 불과하다고 믿으며 비즈니스 고객이 필요로 하고 원한다고 말하는 기능을 계속해서 구축할 계획입니다.  많은 브랜드와 판매자가 아마존 마켓플레이스에서 제품을 성공적으로 판매하고 있지만 자체 소비자 직접 웹사이트를 시작한 많은 브랜드와 판매자도 있습니다. 이러한 판매자의 과제 중 하나는 보기에서 구매로의 전환을 유도하는 것입니다. 우리는 이 문제를 해결하기 위해 Buy with Prime을 개발했습니다. Prime으로 구매하면 타사 브랜드 및 판매자가 자체 웹사이트에서 대규모 Amazon Prime 멤버십에 제품을 제공하고 해당 고객에게 Amazon 계정을 통해 빠른 무료 프라임 배송 및 원활한 결제를 제공할 수 있습니다. Buy with Prime은 Amazon Pay 및 Fulﬁllment by Amazon을 통해 Amazon에서 제품 보관, 피킹, 포장, 배송, 결제 및 모든 반품을 처리하는 등 판매자에게 몇 가지 추가 혜택을 제공합니다. Buy with Prime은 최근 모든 미국 판매자에게 제공되었습니다. 지금까지 Buy with Prime은 타사 쇼핑 사이트에서 구매자 전환을 평균 25% 증가시켰습니다. 가맹점은 더 많은 판매를 전환하고 이러한 배송을 더 쉽게 이행할 수 있다는 사실에 흥분하고 있으며, 프라임 회원은 더 많은 목적지에서 프라임 혜택을 사용할 수 있다는 점에 만족하고 있으며 프라임으로 구매를 통해 더 많은 웹에서 쇼핑 경험을 개선할 수 있습니다.  국제적으로 확장하고, 아직 아마존의 초기 단계인 대규모 소매 시장 부문을 추구하고, 판매자가 자신의 웹사이트에서 보다 효과적으로 판매할 수 있도록 돕기 위해 우리의 고유한 자산을 사용하는 것은 우리에게 어느 정도 자연스러운 확장입니다. 핵심 비즈니스에서 더 멀리 떨어져 있지만 고유한 기회가 있는 투자도 몇 가지 있습니다. 2003년에는 AWS가 전형적인 예였습니다. 2023년에는 Amazon Healthcare와 Kuiper가 잠재적인 아날로그입니다.  의료 분야에서 우리의 초기 노력은 전자 상거래에서 크게 벗어난 것처럼 느껴지지 않는 약국에서 시작되었습니다. 수년 동안 Amazon 고객은 현재 공급자에 대한 불만이 커지면서 언제 온라인 약국을 제공할지 물었습니다. 2020년에 출시된 Amazon Pharmacy는 Prime 회원에게 투명한 가격, 손쉬운 리필 및 비용 절감을 제공하는 풀 서비스 온라인 약국입니다. 비즈니스는 빠르게 성장하고 있으며 혁신을 계속하고 있습니다. 예를 들어 Amazon Pharmacy는 최근 RxPass를 출시했습니다. RxPass는 매월 5달러의 정액 요금으로 Prime 회원이 고혈압, 위산 역류 및 불안과 같은 수십 가지 일반적인 조건에 필요한 적격 처방약을 원하는 만큼 받을 수 있습니다. . 그러나 고객은 Amazon이 비효율적이고 만족스럽지 못한 광범위한 의료 경험에 대한 더 나은 대안을 제공하기를 바라는 강한 열망을 계속 표명했습니다. 우리는 일차 진료가 환자 여정에서 널리 퍼진 첫 번째 중지이기\n",
      "\n",
      "위의 내용을 Korean으로 최종적으로 요약합니다:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m때문에 시작하기로 결정했습니다. 우리는 Amazon Care와 같은 일부 초기 Amazon 실험을 포함하여 기존 환경을 광범위하게 평가하고 연구했습니다. 이 과정에서 우리는 One Medical의 환자 중심 경험이 우리의 미래 사업을 구축하기 위한 훌륭한 기반임을 확인했습니다. 그리고 2022년 7월에 One Medical 인수를 발표했습니다. 고객님들이 원메디컬에 대해 좋아하는 요소가 몇가지 있습니다. 환자가 채팅이나 화상 회의를 통해 의사와 문제를 쉽게 논의할 수 있는 환상적인 디지털 앱이 있습니다. 실제 방문이 필요한 경우 One Medical은 미국 전역의 도시에 사무실을 두고 환자가 당일 또는 익일 약속을 예약할 수 있습니다. One Medical은 각 도시의 전문의와 관계를 맺고 있으며 지역 병원 시스템과 긴밀히 협력하여 전문의를 쉽게 만날 수 있으므로 One Medical 회원은 필요할 때 이러한 리소스에 신속하게 액세스할 수 있습니다. 앞으로 우리는 One Medical과 Amazon이 고객을 위한 1차 진료의 모습을 변화시키기 위해 계속해서 함께 혁신할 것이라고 굳게 믿습니다.  Kuiper는 Amazon이 고객 요구 사항이 높은 영역에서 장기적으로 고객을 위해 혁신한 또 다른 예입니다. Kuiper에 대한 우리의 비전은 현재 없는 전 세계에 고품질 광대역 인터넷 서비스를 제공하는 저궤도 위성 시스템을 만드는 것입니다. 인터넷에 안정적으로 액세스할 수 없는 수억 개의 가정과 기업이 있습니다. 사람들이 온라인 교육 과정을 수강하고, 금융 서비스를 사용하고, 사업을 시작하고, 쇼핑을 하고, 엔터테인먼트를 즐기는 것부터 서비스 범위, 효율성 및 운영을 개선하는 기업 및 정부에 이르기까지 안정적인 연결로 무엇을 할 수 있을지 상상해 보십시오. Kuiper는 접근성뿐만 아니라 경제성도 제공할 것입니다. 우리 팀은 액세스 장벽을 낮출 저비용 안테나(예: 고객 단말기)를 개발했습니다. 우리는 최근 오버헤드를 통과하는 위성과 통신할 새 터미널을 공개했으며 표준 주거용 버전을 개당 $400 미만으로 생산할 수 있을 것으로 기대합니다. 그것들은 작습니다: 11인치 정사각형, 1인치 두께, 마운팅 브래킷을 제외하고 무게는 5파운드 미만이지만 초당 최대 400메가비트의 속도를 제공합니다. 그리고 Amazon에서 설계한 베이스밴드 칩으로 구동됩니다. 우리는 올해 전체 엔드-투-엔드 통신 네트워크를 테스트하기 위해 두 개의 프로토타입 위성을 발사할 준비를 하고 있으며 2024년에는 상용 고객과 함께 베타 테스트를 할 계획입니다. 지금까지 Kuiper에 대해 공유한 내용에 대한 고객 반응은 매우 긍정적이며 Kuiper가 Amazon에 매우 큰 잠재적 기회를 제공한다고 믿습니다. 또한 처음에는 자본 집약적이라는 점에서 AWS와 몇 가지 유사점을 공유하지만 잠재 소비자, 기업 및 정부 고객 기반이 넓고 상당한 수익 및 영업 이익 잠재력이 있으며 기술 및 창의적 능력을 갖춘 회사가 상대적으로 적다는 점에서 AWS와 유사합니다. 그것을 추구하는 투자 가설로.  제가 언급할 마지막 투자 영역은 Amazon이 앞으로 수십 년 동안 모든 비즈니스 영역에서 발명할 수 있도록 설정하는 핵심이며 대규모 언어 모델(\"LLM\") 및 생성 AI입니다. 머신 러닝은 수십 년 동안 유망한 기술이었지만 기업에서 널리 사용되기 시작한 것은 불과 5~10년 전입니다. 이러한\n",
      "\n",
      "위의 내용을 Korean으로 최종적으로 요약합니다:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m변화는 그 어느 때보다 낮은 가격으로 더 많은 양의 컴퓨팅 용량에 대한 액세스를 포함하여 몇 가지 요인에 의해 주도되었습니다. Amazon은 25년 동안 기계 학습을 광범위하게 사용해 왔으며 개인화된 전자 상거래 권장 사항부터 주문 처리 센터 선택 경로, Prime Air용 드론, Alexa, AWS가 제공하는 많은 기계 학습 서비스(AWS가 가장 광범위한 기계를 보유한 곳) 모든 클라우드 공급자의 학습 기능 및 고객 기반). 보다 최근에는 GeneraTve AI라고 하는 새로운 형태의 기계 학습이 등장하여 기계 학습 채택을 크게 가속화할 것이라고 약속합니다. 제너레이티브 AI는 매우 큰 언어 모델(최대 천억 개의 매개변수에 대해 훈련되고 계속 증가하고 있음)을 기반으로 하며 광범위한 데이터 세트에 걸쳐 매우 일반적이고 광범위한 리콜 및 학습 기능을 갖추고 있습니다. 우리는 한동안 자체 LLM에 대해 작업해 왔으며 이것이 거의 모든 고객 경험을 변화시키고 개선할 것이라고 믿으며 모든 소비자, 판매자, 브랜드 및 제작자 경험에 걸쳐 이러한 모델에 계속해서 상당한 투자를 할 것입니다. 또한 AWS에서 수년간 해왔듯이 모든 규모의 회사가 제너레이티브 AI를 활용할 수 있도록 이 기술을 민주화하고 있습니다. AWS는 Trainium 및 InferenTa에서 가장 가격 대비 성능이 뛰어난 기계 학습 칩을 제공하므로 소규모 및 대규모 기업이 프로덕션 환경에서 LLM을 교육하고 실행할 수 있습니다. 우리는 회사가 다양한 LLM 중에서 선택하고 고객이 사용하는 데 익숙한 모든 AWS 보안, 개인 정보 보호 및 기타 기능을 갖춘 애플리케이션을 구축할 수 있도록 합니다. 또한 실시간으로 코드 제안을 생성하여 개발자 생산성을 혁신하는 AWS의 CodeWhisperer와 같은 애플리케이션을 제공하고 있습니다. LLM과 GeneraTve AI가 그렇게 변혁적일 것이라고 생각하기 때문에 전체 편지를 쓸 수 있지만 향후 편지로 남겨두겠습니다. LLM과 GeneraTve AI가 고객, 주주 및 Amazon에게 큰 문제가 될 것이라고 가정해 보겠습니다.  그래서 마지막으로 저는 우리가 이 도전적인 거시경제 시대에 진입했을 때보다 더 강력한 위치에서 등장할 것이라고 낙관합니다. 여기에는 몇 가지 이유가 있으며 위에서 많은 이유를 언급했습니다. 그러나 우리의 엄청난 미래 기회를 강조하는 두 가지 비교적 간단한 통계가 있습니다. 우리는 2022년에 4,340억 달러 규모의 소비자 비즈니스를 보유하고 있지만, 전 세계 소매업의 전체 시장 부문 점유율의 대부분은 여전히 물리적 매장에 있습니다(약 80%). 그리고 2022년에 AWS 수익이 800억 달러이고 글로벌 IT 지출의 약 90%가 여전히 온프레미스에 있지만 아직 클라우드로 마이그레이션하지 않는 글로벌 IT 지출에 대한 유사한 이야기입니다. 우리가 이미 보고 있는 것처럼 이러한 방정식이 꾸준히 역전됨에 따라 우리는 선도적인 고객 경험, 끊임없는 발명, 고객 중심 및 노력이 향후 몇 년 동안 상당한 성장을 가져올 것이라고 믿습니다. 그리고 물론 여기에는 Amazon에서 추구하는 다른 비즈니스와 경험이 포함되지 않으며 모두 아직 초기 단계입니다.  저는 우리의 최고의 날이 우리 앞에 와 있다고 굳게 믿으며, 그렇게 되도록 Amazon의 팀원들과 협력하기를 기대합니다.\n",
      "\n",
      "위의 내용을 Korean으로 최종적으로 요약합니다:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 아마존의 미래 전망에 대해 다음과 같이 요약할 수 있습니다:\\n\\n- 기계학습과 제너레이티브 AI 기술이 고객 경험을 크게 변화시킬 것으로 예상됨\\n\\n- AWS를 통해 기계학습 칩과 인프라를 저렴하게 제공, 모든 규모 기업이 AI 활용 가능\\n\\n- 아직 소매와 IT 시장의 대부분이 온프레미스에 있어 성장 여지가 많음\\n\\n- 고객 중심의 혁신과 노력으로 향후 몇 년 간 상당한 성장이 기대됨\\n\\n- 아마존은 기술 선도와 꾸준한 발명을 통해 어려운 경제 환경에서도 성공 가능할 것\\n\\n요약하면 아마존은 AI/클라우드 기술 리더십을 바탕으로 시장 점유율 확대와 지속 성장을 이룰 것으로 낙관하고 있다는 것입니다.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "prompt_template = \"{text}\\n\\n위의 내용을 Korean으로 요약합니다:\"\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "\n",
    "refine_template = \"{text}\\n\\n위의 내용을 Korean으로 최종적으로 요약합니다:\"\n",
    "refine_prompt = PromptTemplate(template=refine_template, input_variables=[\"text\"])\n",
    "\n",
    "chain = load_summarize_chain(\n",
    "    llm, chain_type=\"refine\", \n",
    "    question_prompt=prompt, \n",
    "    refine_prompt=refine_prompt,\n",
    "    verbose=True)\n",
    "\n",
    "chain.run(docs) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1d048a-6575-4fb5-856f-8b136a61b4d4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
